{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "word_embedding.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2nRY4GyKWqL",
        "colab_type": "text"
      },
      "source": [
        "# Tensorflow 2 - BERT Experiment\n",
        "\n",
        "Author: Rick Qiu \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjF9gyx98uTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "680610b6-9014-47c1-e2bc-f12a831301e7"
      },
      "source": [
        "%reset"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvh3ECwPcRI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uncomment the pip install commands to install required packages\n",
        "#!pip install bert-for-tf2\n",
        "#!pip install sentencepiece\n",
        "#!pip install tensorflow_hub"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dotZjUvecRI8",
        "colab_type": "code",
        "outputId": "3d47c0a2-737b-4ca3-f321-79977bb25b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bert\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.models import  Model\n",
        "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tqdm import tqdm\n",
        "from collections import namedtuple\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.2.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uH1zw2Pa13m",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W379xRxlMbtb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the train.csv into Pandas dataframe\n",
        "df=pd.read_csv('/content/drive/My Drive/data/train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgSWxw7-QMNv",
        "colab_type": "code",
        "outputId": "12c6a565-c59d-41b6-ed63-30b5017001dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Print the column names and the total number of training examples\n",
        "print('Column names:\\n', df.columns.values)\n",
        "print(\"\\nTotal number of examples:\\n\", df.shape[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Column names:\n",
            " ['id' 'comment_text' 'toxic' 'severe_toxic' 'obscene' 'threat' 'insult'\n",
            " 'identity_hate']\n",
            "\n",
            "Total number of examples:\n",
            " 159571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_uP_hOAR_ac",
        "colab_type": "code",
        "outputId": "4b3279f6-a8c5-4274-a4d5-8a85a1f3e6e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Identify missing values\n",
        "df.apply(lambda x: sum(x.isnull()), axis=0)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "comment_text     0\n",
              "toxic            0\n",
              "severe_toxic     0\n",
              "obscene          0\n",
              "threat           0\n",
              "insult           0\n",
              "identity_hate    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJKQ3KpHaYjk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shuffle the dataset\n",
        "df = df.sample(frac=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzZQoMZ6U6ft",
        "colab_type": "code",
        "outputId": "c7c42144-c980-41fa-d17e-09adb6491f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "# Plot frequencies of toxic comments per class\n",
        "classes = df.iloc[:,2:]\n",
        "classes_freq = classes.sum(axis=0)\n",
        "print(classes_freq)\n",
        "classes_freq.plot(kind='bar')\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic            15294\n",
            "severe_toxic      1595\n",
            "obscene           8449\n",
            "threat             478\n",
            "insult            7877\n",
            "identity_hate     1405\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f81dea26cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEzCAYAAADTrm9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAe/UlEQVR4nO3de5hcdZ3n8ffHBARRDJeImGRIxIgbWFBsId5GgZEEUMIqIOhIxEh2FAUvK4LuyCyXHUAfWVkFRYgEZYGAuGQFxQyXZRwhEO536QkgyYC0BJDRFQh+9o/zayya7ly6qut0V31ez9NP1/meU13fepLuT51zfud3ZJuIiOhuL6u7gYiIqF/CICIiEgYREZEwiIgIEgYREUHCICIiWIcwkLRA0mOS7hxQ/6ykeyXdJemUhvoxknol3SdpVkN9dqn1Sjq6oT5N0tJSv1DShq16cxERsW7WZc/gHGB2Y0HSbsAcYCfb2wPfKPUZwEHA9uU5p0saJ2kc8B1gL2AGcHDZFuBk4FTbbwCeAOY1+6YiImL9rDUMbF8LrBpQ/hRwku1nyjaPlfoc4ALbz9h+AOgFdilfvbaX234WuACYI0nA7sDF5fkLgf2afE8REbGexg/zeW8E3i3pROBPwH+xfSMwCbi+YbsVpQbw8ID6rsAWwJO2Vw+y/UtImg/MB9hkk03e+qY3vWmY7UdEdKebbrrpd7YnDqwPNwzGA5sDM4G3AYskvb6J/taJ7TOBMwF6enq8bNmykX7JiIiOIumhwerDDYMVwCWuJja6QdKfgS2BlcCUhu0mlxpD1B8HJkgaX/YOGrePiIg2Ge7Q0v8N7AYg6Y3AhsDvgMXAQZJeLmkaMB24AbgRmF5GDm1IdZJ5cQmTq4H9y8+dC1w63DcTERHDs9Y9A0nnA+8FtpS0AjgWWAAsKMNNnwXmlj/sd0laBNwNrAYOt/18+TmfAa4AxgELbN9VXuLLwAWSTgBuAc5u4fuLiIh1oLE6hXXOGURErD9JN9nuGVjPFcgREZEwiIiIhEFERJAwiIgIhn+dwZg19ejL2vp6D560T1tfLyJiOLJnEBERCYOIiEgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRAREaxDGEhaIOmxcr/jgeu+KMmStizLknSapF5Jt0vauWHbuZLuL19zG+pvlXRHec5pktSqNxcREetmXfYMzgFmDyxKmgLsCfymobwXML18zQfOKNtuDhwL7ArsAhwrabPynDOAwxqe95LXioiIkbXWMLB9LbBqkFWnAkcBbqjNAc515XpggqStgVnAEturbD8BLAFml3Wb2r7etoFzgf2ae0sREbG+hnXOQNIcYKXt2wasmgQ83LC8otTWVF8xSH2o150vaZmkZX19fcNpPSIiBrHeYSDpFcBXgK+1vp01s32m7R7bPRMnTmz3y0dEdKzh7BlsC0wDbpP0IDAZuFnSa4GVwJSGbSeX2prqkwepR0REG613GNi+w/ZrbE+1PZXq0M7Oth8FFgOHlFFFM4GnbD8CXAHsKWmzcuJ4T+CKsu73kmaWUUSHAJe26L1FRMQ6WpehpecD1wHbSVohad4aNr8cWA70At8HPg1gexVwPHBj+Tqu1CjbnFWe86/Az4b3ViIiYrjGr20D2wevZf3UhscGDh9iuwXAgkHqy4Ad1tZHRESMnFyBHBERCYOIiEgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiWLd7IC+Q9JikOxtqX5d0r6TbJf1E0oSGdcdI6pV0n6RZDfXZpdYr6eiG+jRJS0v9QkkbtvINRkTE2q3LnsE5wOwBtSXADrZ3BH4NHAMgaQZwELB9ec7pksZJGgd8B9gLmAEcXLYFOBk41fYbgCeAeU29o4iIWG9rDQPb1wKrBtR+YXt1WbwemFwezwEusP2M7QeAXmCX8tVre7ntZ4ELgDmSBOwOXFyevxDYr8n3FBER66kV5ww+AfysPJ4EPNywbkWpDVXfAniyIVj66xER0UZNhYGkrwKrgfNa085aX2++pGWSlvX19bXjJSMiusKww0DSx4H3Ax+17VJeCUxp2GxyqQ1VfxyYIGn8gPqgbJ9pu8d2z8SJE4fbekREDDCsMJA0GzgK2Nf2HxtWLQYOkvRySdOA6cANwI3A9DJyaEOqk8yLS4hcDexfnj8XuHR4byUiIoZrXYaWng9cB2wnaYWkecC3gVcBSyTdKum7ALbvAhYBdwM/Bw63/Xw5J/AZ4ArgHmBR2Rbgy8AXJPVSnUM4u6XvMCIi1mr82jawffAg5SH/YNs+EThxkPrlwOWD1JdTjTaKiIia5ArkiIhIGERERMIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERHBut0DeYGkxyTd2VDbXNISSfeX75uVuiSdJqlX0u2Sdm54ztyy/f2S5jbU3yrpjvKc0ySp1W8yIiLWbF32DM4BZg+oHQ1caXs6cGVZBtgLmF6+5gNnQBUewLHArlT3Oz62P0DKNoc1PG/ga0VExAhbaxjYvhZYNaA8B1hYHi8E9muon+vK9cAESVsDs4AltlfZfgJYAswu6za1fb1tA+c2/KyIiGiT4Z4z2Mr2I+Xxo8BW5fEk4OGG7VaU2prqKwapR0REGzV9Arl8oncLelkrSfMlLZO0rK+vrx0vGRHRFYYbBr8th3go3x8r9ZXAlIbtJpfamuqTB6kPyvaZtnts90ycOHGYrUdExEDDDYPFQP+IoLnApQ31Q8qoopnAU+Vw0hXAnpI2KyeO9wSuKOt+L2lmGUV0SMPPioiINhm/tg0knQ+8F9hS0gqqUUEnAYskzQMeAg4sm18O7A30An8EDgWwvUrS8cCNZbvjbPeflP401YiljYGfla+IiGijtYaB7YOHWLXHINsaOHyIn7MAWDBIfRmww9r6iIiIkZMrkCMiImEQEREJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERwTrc3CZitJh69GVtfb0HT9qnra8XUafsGURERMIgIiKaDANJn5d0l6Q7JZ0vaSNJ0yQtldQr6UJJG5ZtX16We8v6qQ0/55hSv0/SrObeUkRErK9hh4GkScARQI/tHYBxwEHAycCptt8APAHMK0+ZBzxR6qeW7ZA0ozxve2A2cLqkccPtKyIi1l+zh4nGAxtLGg+8AngE2B24uKxfCOxXHs8py5T1e0hSqV9g+xnbDwC9wC5N9hUREeth2GFgeyXwDeA3VCHwFHAT8KTt1WWzFcCk8ngS8HB57uqy/RaN9UGe8yKS5ktaJmlZX1/fcFuPiIgBhj20VNJmVJ/qpwFPAhdRHeYZMbbPBM4E6Onp8Ui+VkS0VoYGj27NHCb6G+AB2322nwMuAd4JTCiHjQAmAyvL45XAFICy/tXA4431QZ4TERFt0EwY/AaYKekV5dj/HsDdwNXA/mWbucCl5fHiskxZf5Vtl/pBZbTRNGA6cEMTfUVExHoa9mEi20slXQzcDKwGbqE6hHMZcIGkE0rt7PKUs4EfSuoFVlGNIML2XZIWUQXJauBw288Pt6+IiFh/TU1HYftY4NgB5eUMMhrI9p+AA4b4OScCJzbTS0REDF+uQI6IiIRBREQkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERJAwiIoKEQUREkDCIiAgSBhERQcIgIiJIGEREBAmDiIggYRARETQZBpImSLpY0r2S7pH0dkmbS1oi6f7yfbOyrSSdJqlX0u2Sdm74OXPL9vdLmtvsm4qIiPXT7J7Bt4Cf234TsBNwD3A0cKXt6cCVZRlgL2B6+ZoPnAEgaXOq+yjvSnXv5GP7AyQiItpj2GEg6dXAXwNnA9h+1vaTwBxgYdlsIbBfeTwHONeV64EJkrYGZgFLbK+y/QSwBJg93L4iImL9NbNnMA3oA34g6RZJZ0naBNjK9iNlm0eBrcrjScDDDc9fUWpD1V9C0nxJyyQt6+vra6L1iIho1EwYjAd2Bs6w/RbgD/zlkBAAtg24idd4Edtn2u6x3TNx4sRW/diIiK7XTBisAFbYXlqWL6YKh9+Wwz+U74+V9SuBKQ3Pn1xqQ9UjIqJNhh0Gth8FHpa0XSntAdwNLAb6RwTNBS4tjxcDh5RRRTOBp8rhpCuAPSVtVk4c71lqERHRJuObfP5ngfMkbQgsBw6lCphFkuYBDwEHlm0vB/YGeoE/lm2xvUrS8cCNZbvjbK9qsq+IiFgPTYWB7VuBnkFW7THItgYOH+LnLAAWNNNLREQMX65AjoiIhEFERCQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBwiAiIkgYREQECYOIiCBhEBERtCAMJI2TdIukn5blaZKWSuqVdGG5PzKSXl6We8v6qQ0/45hSv0/SrGZ7ioiI9dOKPYMjgXsalk8GTrX9BuAJYF6pzwOeKPVTy3ZImgEcBGwPzAZOlzSuBX1FRMQ6aioMJE0G9gHOKssCdgcuLpssBPYrj+eUZcr6Pcr2c4ALbD9j+wGgF9ilmb4iImL9NLtn8D+Ao4A/l+UtgCdtry7LK4BJ5fEk4GGAsv6psv0L9UGe8yKS5ktaJmlZX19fk61HRES/YYeBpPcDj9m+qYX9rJHtM2332O6ZOHFiu142IqLjjW/iue8E9pW0N7ARsCnwLWCCpPHl0/9kYGXZfiUwBVghaTzwauDxhnq/xudEREQbDHvPwPYxtifbnkp1Avgq2x8Frgb2L5vNBS4tjxeXZcr6q2y71A8qo42mAdOBG4bbV0RErL9m9gyG8mXgAkknALcAZ5f62cAPJfUCq6gCBNt3SVoE3A2sBg63/fwI9BUREUNoSRjYvga4pjxeziCjgWz/CThgiOefCJzYil4iImL95QrkiIhIGERERMIgIiJIGEREBAmDiIggYRARESQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQMIiICBIGERFBE2EgaYqkqyXdLekuSUeW+uaSlki6v3zfrNQl6TRJvZJul7Rzw8+aW7a/X9Lc5t9WRESsj2b2DFYDX7Q9A5gJHC5pBnA0cKXt6cCVZRlgL2B6+ZoPnAFVeADHArtS3Tv52P4AiYiI9hh2GNh+xPbN5fHTwD3AJGAOsLBsthDYrzyeA5zryvXABElbA7OAJbZX2X4CWALMHm5fERGx/lpyzkDSVOAtwFJgK9uPlFWPAluVx5OAhxuetqLUhqoP9jrzJS2TtKyvr68VrUdEBC0IA0mvBH4MfM727xvX2TbgZl+j4eedabvHds/EiRNb9WMjIrpeU2EgaQOqIDjP9iWl/Nty+Ify/bFSXwlMaXj65FIbqh4REW3SzGgiAWcD99j+ZsOqxUD/iKC5wKUN9UPKqKKZwFPlcNIVwJ6SNisnjvcstYiIaJPxTTz3ncDHgDsk3VpqXwFOAhZJmgc8BBxY1l0O7A30An8EDgWwvUrS8cCNZbvjbK9qoq+IiFhPww4D278ENMTqPQbZ3sDhQ/ysBcCC4fYSlalHX9bW13vwpH3a+noRMXJyBXJERCQMIiKiuXMGERFRjPXDtNkziIiIhEFERCQMIiKChEFERJAwiIgIEgYREUHCICIiSBhERAQJg4iIIGEQEREkDCIigoRBRESQieoiRo2xPtFZjG3ZM4iIiIRBRESMojCQNFvSfZJ6JR1ddz8REd1kVISBpHHAd4C9gBnAwZJm1NtVRET3GBVhAOwC9NpebvtZ4AJgTs09RUR0Ddmuuwck7Q/Mtv3JsvwxYFfbnxmw3XxgflncDrivjW1uCfyuja/XTp383iDvb6zL+2utbWxPHFgcU0NLbZ8JnFnHa0taZrunjtceaZ383iDvb6zL+2uP0XKYaCUwpWF5cqlFREQbjJYwuBGYLmmapA2Bg4DFNfcUEdE1RsVhIturJX0GuAIYByywfVfNbQ1Uy+GpNunk9wZ5f2Nd3l8bjIoTyBERUa/RcpgoIiJqlDCIiIiEQUREJAyiw0l6Rd09tJqkl69LbSyTdMC61KJ1EgZDKMNcN2pY3ljS1Po6ai1Jh0ua0LC8maRP19lTK0l6h6S7gXvL8k6STq+5rVa5bh1rY9kx61gbs8rflO3q7qPfqBhaOkpdBLyjYfn5UntbPe203GG2v9O/YPsJSYcBnfIH81RgFuV6Fdu3SfrreltqjqTXApOAjSW9BVBZtSnQEXtAkvYC9gYmSTqtYdWmwOp6umo9SR8AvgFsCEyT9GbgONv71tVTwmBo48ukeQDYfrZcENcpxkmSy9jiMnNsJ70/bD8sqbH0fF29tMgs4ONUV+h/s6H+NPCVOhoaAf8G3ATsW773exr4fC0djYx/oJqg8xoA27dKmlZnQwmDofVJ2tf2YgBJc+isybJ+Dlwo6Xtl+T+XWqd4WNI7AEvaADgSuKfmnppieyGwUNKHbP+47n5Ggu3bgNsk/ch2x+wJDOI5208N+LBS60VfuehsCJK2Bc4DXke1O/4wcIjt3lobaxFJL6MKgD1KaQlwlu2x/ukZAElbAt8C/obq3+8XwJG2H6+1sRaRtA+wPfDCeS3bx9XXUWtIuoM1/FG0vWMb2xkxks4GrgSOBj4EHAFsYPvvauspYbBmkl4JYPvf6+4lAkDSd6nOEewGnAXsD9xge16tjbWApG3WtN72Q+3qZSSVUW5fBfYspSuA420/U1tPCYMXk/S3tn8k6QuDrbf9zcHqY4WkRbYPHOoTWAd98poIHAZMpeFwqO1P1NVTq0i63faODd9fCfzM9rvr7i3WjaQDbF+0tlo75ZzBS21Svr+q1i5GzpHl+/tr7WLkXQr8M/BPjP0TxwP9v/L9j5JeBzwObF1jPy0n6Wn+8mFlQ2AD4A+2N62vq5Y6hmp04tpqbZMwGMD298r3/zZwXSeMJrL9SHm4ie27G9dJei/QEbvhwCtsf7nuJkbIT8s1Il8Hbqb6o3lWvS21lu0XPoypOss6B5hZX0etMZqHzuYw0RAkXQN83PaDZfltVCdYd6qzr1aRdCfwQ+AUqpOQpwA9tt9ea2MtIukE4Fe2L6+7l5FUrjzeyPZTdfcy0iTdYvstdffRDEk7AW8GjgO+1rDqaeBq20/U0hgJgyFJmkU1GuU0qgt99gI+afvmWhtrEUmbACcDb6U6JHYecLLtP9faWIuUwwybAM+WLwHuhMMM5eTjF4G/sn2YpOnAdrZ/WnNrLSPpgw2LLwN6gPd00IeVDWw/V3cfjXKYaAi2r5D0d1RDLn8HvMX2ozW31UrPUR173phqz+CBTgkCePFhhg70A6oLsvr/MK6kOtbcMWEAfKDh8WrgQapDRZ1iqqR/BGbw4uHBr6+roYTBECT9PXAg8NfAjsA1kr5o+7J6O2uZG6lOsr4N2BL4brmYqSMmAyvHmT8KTLN9vKQpwNa2b6i5tVbY1vaHJR0MYPuPGnD10lhn+9C6exhhPwCOpZo2ZTfgUGqeKy4T1Q1tC2AX29eVk8qzgM/V3FMrzbP9NdvP2X7E9hw6677Tp1N9cv5IWf534DtDbz6mPCtpY8pom3KBZG3j00eCpFMkbSppA0lXSuqT9Ld199VCG9u+kupQ/UO2/wHYp86GsmcwBNufk7SVpP4rdG+w/b5am2qt2yQdQbXnA9UcKd8bevMxZ1fbO0u6BV6YiG/MjwYrjqWaOmSKpPOAd1LNWdRJ9rR9lKT/RHWI6IPAtcCPau2qdZ4pswDcX+7/vhJ4ZZ0NZc9gCGXu9BuAA6gOFy2VtH+9XbXUGVQnj08vX/2PO8VzZfK9/k/PE4Exf06k/AHZjOqP48eB86lGgV1TY1sjof+D6j7ARR04WupIqqvIj6D63fsYMLfOhjKaaAiSbgPeZ/uxsjwR+KcOGlp628D3MlhtrJL0UeDDwM7AQqopG/5rnVd4toqkZbZ76u5jJEk6CdiPapDDLsAE4Ke2d621sQ6WMBiCpDts/8eG5ZcBtzXWxjJJNwMH2P7Xsvx64GLbO9fbWetIehPVRHwCrrQ9pmct7Vf+UP4OuBD4Q3/d9qramhoBkjYHnrL9fBlOu2mnjOiT9EbgS8A2vHi6lN1r6ylhMDhJpwA7Ue2GQ/Up8/ZOuaq1nAv5AbCc6o/lNsAnbF9Va2MtImkmcJftp8vypsB/sL203s6aJ+mBQcquc1jiSChTkE/lxX8sz62toRYqRx6+SzVE+IXpUmzfNOSTRrqnhMHgJJ0MLAXeVUr/DMzsoDDov2du/2337gOoc9bEVionjnduuHnPy4BlnbTn08kk/RDYFriVv/yxtO0j6uuqdSTdZPutdffRKGEwBEk3D/zD0T9LZF09tdIQ7+8ltbFK0q223zyg1kn/fh37qRlA0j3ADHfYH6hy6AuqE8ePAT+hYVhwnYf6MrR0AEmfAj4NvF7S7Q2rXgX8Sz1dtY664D66xfIydPaMsvxpqkNiY95Qn5qBjgkD4E7gtcAja9twjLmJ6t+q//fuSw3rDNR2qC97BgNIejXV0L1/pLoLUb+nO+EEnaS5VEMSe6iuQu7/T/l7YKHtS2pqraUkvYZqXqndqX7JrgQ+1z86bCzr1E/NjSRdTTWh2w28+JNzbTeMbydJ77O9pK2v2cH/n2INtJb76Eqa6+qeuzHKSLoIOKJhOvKOI+k9g9Vt/99291KHOg7ZJgxiUGP9/EEZDXYC1Tj1n1PNL/V522P2ClZJ/4dqL+dVdPGn5m5Qx3TdOWcQQxnrE5914nQG36D6dzmZ6oKsfv21MU/SL22/a8CdzqCDpiBfR23/lJ4wiKGM9V3Gl0xnMNYn9uw/RFLmwn/R4ZIycd2YZ/td5XsnT0E+KiUMYihj+y9ndWvIe6kOE32qTCfyp5p7akqnj3SLF3mw3S+YcwYxKEnftv2ZuvtoRqdNZ9DpI926iaSbgAXA/6rzVpeNEgZdStJWwH8HXmd7L0kzgLfbPrvm1lpC0kZUn6LfRXXI65fAGbbH9N5BdAZJb6C6oc2HgWVUU8P8os7hwgmDLiXpZ1T/Ab9qeydJ44FbOmgivkVUNxnvP2H8EWBCp9zJLTpDmSbl/VQXRz5P9Tv5rTr29HLOoHttaXuRpGMAbK+W9PzanjSG7GB7RsPy1ZLurq2biAEk7Ui1d7A38GPgPKo92auohg63VcKge/1B0hb85eYvM4FOuoHIzZJm2r4eQNKuVLvjEbUr5wyeBM4Gjm6YIHKppHfW0lMOE3UnSTsD/xPYgWoemInA/rZvX+MTRzlJd1AF3AZUM7L+pixvA9w7YG8hohaSXm97+YDaNNuDTU/eFtkz6ELldpDvKV/bUQ0jvc/2c7U21hrvb3i8GfDu8vhaqk9iEaPBxVR34RtYq21a64RBFypDLQ+2fSpwV939tJLthwAkHQl8EriEKux+CHyfam8oohbl7nvbA6+W9MGGVZsCG9XTVSWHibqUpFOpDqUMvHXizbU11ULloqy32/5DWd4EuK5T7mcQY5OkOVRTiewLLG5Y9TRwge1f1dIYCYOuVaYIHsh13oO1lcq5g7f1X1dQrju4sVOGzsbYJunttq+ru49GOUzUpWzvVncPI+wHVCMzflKW96MauRFRG0lH2T4F+Iikgweur/O2ngmDLtXpVyDb/qaka/jLPawPtX1LjS1FANxTvo+6Yc45TNSlOv0K5IjRTNIBti9aW62dXlbXC0fttrS9CPgzVFcg85f76UbEyDpmHWttk8NE3avTr0COGHUk7UU1/cQkSac1rNoUWF1PV5WEQff6ItXQtm0l/QvlCuR6W4roeP9Gdb5gX+CmhvrTwOdr6ajIOYMuVs4TdNoVyBGjXrlb3aj6fcs5gy5VLso6CviT7TtH23/MiA63i6Qlkn4tabmkByQtX/vTRk72DLqUpG2obqzxYaqTyBcCi2z/ptbGIrpAuSXr56kOFb0wcMP247X1lDAISdOBvwc+antc3f1EdDpJS23vWncfjXICuYsN2Dt4nuqwUUSMvKslfZ1qIsX+exnUOjdY9gy6lKSlVBPVXQRcOHBu9YgYOaNxbrCEQZeStJ3t++ruIyJGh4wm6l5PSjq7TEuBpBmS5tXdVEQ3kLTVaPv9Sxh0r3OAK4DXleVfA5+rrZuI7nIOo+z3L2HQvTI3UUR9Rt3vX8Kge2Vuooj6jLrfvwwt7V5fIHMTRdRl1P3+JQy617bAXsAU4EPAruT/Q0Rb2L5Z0nsYRXODZWhpl5J0u+0dJb0LOB74BvC10XZVZEQnkfTBNa23fUm7ehkonwS7V//Jqn2A79u+TNIJdTYU0QU+UL6/BngHcFVZ3g34FdUVybVIGHSvlZK+B7wPOFnSy8mAgogRZftQAEm/AGbYfqQsb0013LQ2+eXvXgdSjXOeZftJYHPgS/W2FNE1pvQHQfFb4K/qagZyziAiou0kfRuYDpxfSh8Gem1/traeEgYREe1XTia/uyxea/sntfaTMIiIiJxAjohoE0m/tP0uSU9Trj7uX0U1hfWmNbWWPYOIiMhoooiIIGEQEREkDCIigoRBREQA/x/1TWYWcpSX3AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESyS2xsQbQlm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://androidkt.com/simple-text-classification-using-bert-in-tensorflow-keras-2-0/\n",
        "MAX_SEQ_LEN=128 # max sequence length\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    \"\"\"Masks: 1 for real tokens and 0 for paddings\"\"\"\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        " \n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"  \n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "def create_single_input(sentence, tokenizer, MAX_LEN):\n",
        "  \"\"\"Create an input from a sentence\"\"\"\n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "  stokens = stokens[:MAX_LEN]\n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        " \n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids, masks, segments\n",
        " \n",
        "def convert_sentences_to_features(sentences, tokenizer):\n",
        "  \"\"\"Convert sentences to features: input_ids, input_masks and input_segments\"\"\"\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        " \n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "    ids,masks,segments=create_single_input(sentence,tokenizer,MAX_SEQ_LEN-2)\n",
        "    assert len(ids) == MAX_SEQ_LEN\n",
        "    assert len(masks) == MAX_SEQ_LEN\n",
        "    assert len(segments) == MAX_SEQ_LEN\n",
        " \n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32), \n",
        "          np.asarray(input_masks, dtype=np.int32), \n",
        "          np.asarray(input_segments, dtype=np.int32)]\n",
        "\n",
        "def create_tonkenizer(bert_layer):\n",
        "    \n",
        "    vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    do_lower_case=bert_layer.resolved_object.do_lower_case.numpy() \n",
        "    tokenizer=bert.bert_tokenization.FullTokenizer(vocab_file,do_lower_case)\n",
        "    return tokenizer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xs6_p8VTgpoy",
        "colab_type": "text"
      },
      "source": [
        "## NLP model based on BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_mFZ2HRcRJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "b3c4d209-125d-42c6-e935-b603faca84a7"
      },
      "source": [
        "def nlp_model(callable_object):\n",
        "    # Load saved BERT base model\n",
        "    bert_layer = hub.KerasLayer(handle=callable_object, trainable=True)  \n",
        "    # BERT model three inputs: ids, masks and segments\n",
        "    input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_ids\")           \n",
        "    input_masks = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_masks\")       \n",
        "    input_segments = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    inputs = [input_ids, input_masks, input_segments]\n",
        "    # BERT model outputs\n",
        "    pooled_output, sequence_output = bert_layer(inputs)\n",
        "    # Add custom layers\n",
        "    x = GlobalAveragePooling1D()(sequence_output)\n",
        "    x = Dropout(0.2)(x)\n",
        "    outputs = Dense(6, activation=\"sigmoid\")(x)\n",
        "    # Construct a new model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = nlp_model(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\")\n",
        "model.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer_4 (KerasLayer)      [(None, 768), (None, 109482241   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_4 (Glo (None, 768)          0           keras_layer_4[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 768)          0           global_average_pooling1d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 6)            4614        dropout_4[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 109,486,855\n",
            "Trainable params: 109,486,854\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViqJURL5qcZJ",
        "colab_type": "text"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XL5LaS68Qo8G",
        "colab_type": "code",
        "outputId": "f99a213e-1fc1-438a-df0d-c5b52f44e0e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create training examples\n",
        "tokenizer = create_tonkenizer(model.layers[3])\n",
        "X_train = convert_sentences_to_features(df[\"comment_text\"].values, tokenizer)\n",
        "y_train = classes.values"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 159571/159571 [02:46<00:00, 960.03it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzSF2HJi5XsY",
        "colab_type": "code",
        "outputId": "dcecaabe-9418-4505-e416-500082808880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "# Train the model\n",
        "epochs=3\n",
        "batch_size=32\n",
        "\n",
        "opt = Adam(learning_rate=0.01, decay=1e-5)\n",
        "model.compile(optimizer=opt, \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath=\"nlp_model.h5\",\n",
        "                               verbose=0,\n",
        "                               save_best_only=True)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='logs',\n",
        "                          histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.2,\n",
        "                    shuffle=True, \n",
        "                    verbose = 1, \n",
        "                    callbacks=[checkpointer, tensorboard])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "   2/3990 [..............................] - ETA: 1:21:54 - loss: 3.1242 - accuracy: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.007123). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.007123). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 108/3990 [..............................] - ETA: 29:37 - loss: 0.2913 - accuracy: 0.7025"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-51981201d582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                     callbacks=[checkpointer, tensorboard])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLcSofFzjVYU",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}