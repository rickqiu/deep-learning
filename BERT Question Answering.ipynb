{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "BERT_Jupyter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickqiu/deep-learning/blob/master/BERT%20Question%20Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tX9nDQnr8AzT"
      },
      "source": [
        "<img src=\"https://upload.wikimedia.org/wikipedia/en/6/6d/Nvidia_image_logo.svg\" style=\"width: 90px; float: right;\">\n",
        "\n",
        "# BERT Question Answering in TensorFlow with Mixed Precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kL-6-WT78AzR"
      },
      "source": [
        "Copyright 2019 NVIDIA Corporation. All Rights Reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FOa47jxd80bS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "f24e1b5f-f0f4-442a-c0a7-df74ab0ca9cf"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jun 30 01:08:11 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Loy_jvmr8AzT"
      },
      "source": [
        "## 1. Overview\n",
        "\n",
        "Bidirectional Embedding Representations from Transformers (BERT), is a method of pre-training language representations which obtains state-of-the-art results on a wide array of Natural Language Processing (NLP) tasks. \n",
        "\n",
        "The original paper can be found here: https://arxiv.org/abs/1810.04805.\n",
        "\n",
        "NVIDIA's BERT is an optimized version of Google's official implementation, leveraging mixed precision arithmetic and tensor cores on V100 GPUS for faster training times while maintaining target accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BXp2mMCx8AzU"
      },
      "source": [
        "### Learning objectives\n",
        "\n",
        "This notebook demonstrates:\n",
        "- Inference on Question Answering (QA) task with BERT Large model\n",
        "- The use/download of fine-tuned NVIDIA BERT models from [NGC](https://ngc.nvidia.com)\n",
        "- Use of Mixed Precision models for Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xLlJiTQN8AzV"
      },
      "source": [
        "## 2. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oiQ5qvJD8Azm"
      },
      "source": [
        "### Pre-Trained NVIDIA BERT TensorFlow Models on NGC\n",
        "\n",
        "<img src=\"https://blogs.nvidia.com/wp-content/uploads/2019/03/18-ngc-software-stack-447x500.png\" style=\"width: 360px;\">\n",
        "\n",
        "We will be using the following configuration of BERT in this example:\n",
        "\n",
        "| **Model** | **Hidden layers** | **Hidden unit size** | **Attention heads** | **Feedforward filter size** | **Max sequence length** | **Parameters** |\n",
        "|:---------:|:----------:|:----:|:---:|:--------:|:---:|:----:|\n",
        "|BERTLARGE|24 encoder|1024| 16|4 x 1024|512|330M|\n",
        "\n",
        "**To do so, we will take advantage of the pre-trained models available on the [NGC Model Registry](https://ngc.nvidia.com/catalog/models).**\n",
        "\n",
        "Among the many configurations available we will download one of these two:\n",
        "\n",
        " - **bert_tf_v2_large_fp32_384**\n",
        "\n",
        " - **bert_tf_v2_large_fp16_384**\n",
        "\n",
        "which are trained on the [SQuaD 2.0 Dataset](https://rajpurkar.github.io/SQuAD-explorer/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5iJR47XD8Azg"
      },
      "source": [
        "We can choose the mixed precision model (which takes much less time to train than the fp32 version) without losing accuracy, with the following flag: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wT8mFmG51eUt",
        "colab": {}
      },
      "source": [
        "use_mixed_precision_model = True"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C08Gf-PH8Azn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "c9538498-2361-4036-a826-51b92e74d3f5"
      },
      "source": [
        "if use_mixed_precision_model:\n",
        "    # bert_tf_v2_large_fp16_384\n",
        "    !mkdir -p /workspace/bert/data/finetuned_model_fp16\n",
        "    !wget -nc -q --show-progress -O /workspace/bert/data/finetuned_model_fp16/bert_tf_v2_large_fp16_384.zip \\\n",
        "    https://api.ngc.nvidia.com/v2/models/nvidia/bert_tf_v2_large_fp16_384/versions/1/zip\n",
        "    !unzip -n -d /workspace/bert/data/finetuned_model_fp16/ /workspace/bert/data/finetuned_model_fp16/bert_tf_v2_large_fp16_384.zip \n",
        "else:\n",
        "    # bert_tf_v2_large_fp32_384\n",
        "    !mkdir -p /workspace/bert/data/finetuned_model_fp32\n",
        "    !wget -nc -q --show-progress -O /workspace/bert/data/finetuned_model_fp32/bert_tf_v2_large_fp32_384.zip \\\n",
        "    https://api.ngc.nvidia.com/v2/models/nvidia/bert_tf_v2_large_fp32_384/versions/1/zip\n",
        "    !unzip -n -d /workspace/bert/data/finetuned_model_fp32/ /workspace/bert/data/finetuned_model_fp32/bert_tf_v2_large_fp32_384.zip "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/workspace/bert/dat 100%[===================>]   3.42G  47.6MB/s    in 68s     \n",
            "Archive:  /workspace/bert/data/finetuned_model_fp16/bert_tf_v2_large_fp16_384.zip\n",
            "  inflating: /workspace/bert/data/finetuned_model_fp16/model.ckpt-8144.data-00000-of-00001  \n",
            "  inflating: /workspace/bert/data/finetuned_model_fp16/model.ckpt-8144.index  \n",
            "  inflating: /workspace/bert/data/finetuned_model_fp16/model.ckpt-8144.meta  \n",
            "  inflating: /workspace/bert/data/finetuned_model_fp16/tf_bert_squad_1n_fp16_gbs32.190523090758.log  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BuE_gCBUp6uD"
      },
      "source": [
        "### NGC Model Scripts\n",
        "\n",
        "While we're at it, we'll also pull down some BERT helper scripts from the [NGC Model Scripts Registry](https://ngc.nvidia.com/catalog/model-scripts/nvidia:bert_for_tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kavDaBXpqd7T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be5babf1-7690-49b5-f9ed-a53e07a936a4"
      },
      "source": [
        "# Download BERT helper scripts\n",
        "!wget -nc --show-progress -O bert_scripts.zip \\\n",
        "     https://api.ngc.nvidia.com/v2/recipes/nvidia/bert_for_tensorflow/versions/1/zip\n",
        "!mkdir -p /workspace/bert\n",
        "!unzip -n -d /workspace/bert bert_scripts.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-30 01:12:01--  https://api.ngc.nvidia.com/v2/recipes/nvidia/bert_for_tensorflow/versions/1/zip\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 54.241.185.37, 54.153.26.224\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|54.241.185.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/recipes/bert_for_tensorflow/versions/1/files.zip?response-content-disposition=attachment%3B%20filename%3D%22files.zip%22&response-content-type=application%2Fzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMSJHMEUCIQDBbyY8hKhSF1c6n8clKbokPz5BnvV4dkaHRLOMFl18ZAIgRpkcCWcmPO3Td9iLw5tYIkrduNQ1I6GP9W63NuhsyccqtAMIIRACGgw3ODkzNjMxMzUwMjciDDVPGhN3pyweaaM54CqRA3OCUjj4%2FW%2BOj%2F7qtg6kxHPaJna%2FHtTJXrvPgGYbw7C5M33OtZgbjFzdBCuUL3%2FmexWIrJ3gjzVnFAuA%2BdrOuCS23i1Epygj0Jil9RmrJ%2BNb5NyURz1UDVqiBD0ihqcw8DKckkZeuzbGck%2BXH4PGkAZuTyFALgkWSEzt%2BK1gZWtx3sm45z9ujeYI%2FysoiYvCeCsetSXcyToAGIIF%2BnO1A46%2FIUEXoxgAWKnuBFsHVItHNlQMqUYxmobp2zTdt%2FTzLDbtYngVZqS8OHiJuX6MrgHs4YwEMxMaaWW8wwM%2FPFexz5E5WnGpfMpKHyCtF6fg6rzd%2Bzoay5fwINaerSrpdY2lNu%2BSCtW6%2Fs0NHoBtFPeaJdx6IgKSUdFo3c33WR%2FPmSVQED6JlsyzdbHuJXlQRNn%2FCYaQsBQ1gd8fuuv1SblFegCjnT4edIO3ZWlaUNxmQAuvl1DgV7SN84TE%2FcjfF8qP9MS0gPPwPhZvqepJPQuCnCkKc39fcTPv56hI3tJVUtVOlSeoPuH6fwrK15BLOSTdMP2B6vcFOusBh%2FIwBmtPxXptIfnhrrY3b647jBb%2FZI%2BgX60Ir%2Fq0radgsrB0Ej%2F%2BHeK3F9tT5DAMJNDSnI3Itls1LCm3GwVk%2FqdeZ1UFgESuBuj89BINldzYviCe77RHiuxoNR00i%2F4IV%2BMn2DnEiaPNmtVObylQo2cm3ckBtrBduwSqwSAdasPi8FCszyQMU7eInWVEc70lxMeGIGZClUEYjfVll9lf95%2BAcK5MTe4bXLPtkUhwJDWhitpcmx8OzE9tPxOr8Ssz0Pb3sT3AIi4bvhvcsTNzH55AvKO6x7mK87gJBIrLW8POewUwisgOX7a0OA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200630T011202Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZT6SJSWOM%2F20200630%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=4f58cc6289eee5cc20546980d56e1f9593e43c370473b3386d9e7685840637ee [following]\n",
            "--2020-06-30 01:12:02--  https://s3.us-west-2.amazonaws.com/prod-model-registry-ngc-bucket/org/nvidia/recipes/bert_for_tensorflow/versions/1/files.zip?response-content-disposition=attachment%3B%20filename%3D%22files.zip%22&response-content-type=application%2Fzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEIj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMSJHMEUCIQDBbyY8hKhSF1c6n8clKbokPz5BnvV4dkaHRLOMFl18ZAIgRpkcCWcmPO3Td9iLw5tYIkrduNQ1I6GP9W63NuhsyccqtAMIIRACGgw3ODkzNjMxMzUwMjciDDVPGhN3pyweaaM54CqRA3OCUjj4%2FW%2BOj%2F7qtg6kxHPaJna%2FHtTJXrvPgGYbw7C5M33OtZgbjFzdBCuUL3%2FmexWIrJ3gjzVnFAuA%2BdrOuCS23i1Epygj0Jil9RmrJ%2BNb5NyURz1UDVqiBD0ihqcw8DKckkZeuzbGck%2BXH4PGkAZuTyFALgkWSEzt%2BK1gZWtx3sm45z9ujeYI%2FysoiYvCeCsetSXcyToAGIIF%2BnO1A46%2FIUEXoxgAWKnuBFsHVItHNlQMqUYxmobp2zTdt%2FTzLDbtYngVZqS8OHiJuX6MrgHs4YwEMxMaaWW8wwM%2FPFexz5E5WnGpfMpKHyCtF6fg6rzd%2Bzoay5fwINaerSrpdY2lNu%2BSCtW6%2Fs0NHoBtFPeaJdx6IgKSUdFo3c33WR%2FPmSVQED6JlsyzdbHuJXlQRNn%2FCYaQsBQ1gd8fuuv1SblFegCjnT4edIO3ZWlaUNxmQAuvl1DgV7SN84TE%2FcjfF8qP9MS0gPPwPhZvqepJPQuCnCkKc39fcTPv56hI3tJVUtVOlSeoPuH6fwrK15BLOSTdMP2B6vcFOusBh%2FIwBmtPxXptIfnhrrY3b647jBb%2FZI%2BgX60Ir%2Fq0radgsrB0Ej%2F%2BHeK3F9tT5DAMJNDSnI3Itls1LCm3GwVk%2FqdeZ1UFgESuBuj89BINldzYviCe77RHiuxoNR00i%2F4IV%2BMn2DnEiaPNmtVObylQo2cm3ckBtrBduwSqwSAdasPi8FCszyQMU7eInWVEc70lxMeGIGZClUEYjfVll9lf95%2BAcK5MTe4bXLPtkUhwJDWhitpcmx8OzE9tPxOr8Ssz0Pb3sT3AIi4bvhvcsTNzH55AvKO6x7mK87gJBIrLW8POewUwisgOX7a0OA%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20200630T011202Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZT6SJSWOM%2F20200630%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=4f58cc6289eee5cc20546980d56e1f9593e43c370473b3386d9e7685840637ee\n",
            "Resolving s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)... 52.218.229.32\n",
            "Connecting to s3.us-west-2.amazonaws.com (s3.us-west-2.amazonaws.com)|52.218.229.32|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 132136 (129K) [application/zip]\n",
            "Saving to: ‘bert_scripts.zip’\n",
            "\n",
            "bert_scripts.zip    100%[===================>] 129.04K   836KB/s    in 0.2s    \n",
            "\n",
            "2020-06-30 01:12:02 (836 KB/s) - ‘bert_scripts.zip’ saved [132136/132136]\n",
            "\n",
            "Archive:  bert_scripts.zip\n",
            "  inflating: /workspace/bert/.dockerignore  \n",
            "  inflating: /workspace/bert/CONTRIBUTING.md  \n",
            "  inflating: /workspace/bert/Dockerfile  \n",
            "  inflating: /workspace/bert/LICENSE  \n",
            "  inflating: /workspace/bert/NOTICE  \n",
            "  inflating: /workspace/bert/README.md  \n",
            "  inflating: /workspace/bert/__init__.py  \n",
            "  inflating: /workspace/bert/create_pretraining_data.py  \n",
            "  inflating: /workspace/bert/data/README.md  \n",
            "  inflating: /workspace/bert/data/bookcorpus/clean_and_merge_text.py  \n",
            "  inflating: /workspace/bert/data/bookcorpus/config.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/create_pseudo_test_set.py  \n",
            "  inflating: /workspace/bert/data/bookcorpus/create_pseudo_test_set.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/preprocessing.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/preprocessing_test_set.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/preprocessing_test_set_xargs_wrapper.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/preprocessing_xargs_wrapper.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/run_preprocessing.sh  \n",
            "  inflating: /workspace/bert/data/bookcorpus/sentence_segmentation_nltk.py  \n",
            "  inflating: /workspace/bert/data/bookcorpus/shard_text_input_file.py  \n",
            "  inflating: /workspace/bert/data/pretrained_models_google/download_models.py  \n",
            "  inflating: /workspace/bert/data/squad/squad_download.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/config.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/create_pseudo_test_set.py  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/create_pseudo_test_set.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/preprocessing.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/preprocessing_test_set.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/preprocessing_test_set_xargs_wrapper.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/preprocessing_xargs_wrapper.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/remove_tags_and_clean.py  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/run_preprocessing.sh  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/shard_text_input_file.py  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/wiki_sentence_segmentation_nltk.py  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/wiki_sentence_segmentation_spacy.py  \n",
            "  inflating: /workspace/bert/data/wikipedia_corpus/wiki_sentence_segmentation_spacy_pipe.py  \n",
            "  inflating: /workspace/bert/extract_features.py  \n",
            "  inflating: /workspace/bert/gpu_environment.py  \n",
            "  inflating: /workspace/bert/modeling.py  \n",
            "  inflating: /workspace/bert/modeling_test.py  \n",
            "  inflating: /workspace/bert/multilingual.md  \n",
            "  inflating: /workspace/bert/optimization.py  \n",
            "  inflating: /workspace/bert/optimization_test.py  \n",
            "  inflating: /workspace/bert/predicting_movie_reviews_with_bert_on_tf_hub.ipynb  \n",
            "  inflating: /workspace/bert/requirements.txt  \n",
            "  inflating: /workspace/bert/run_classifier.py  \n",
            "  inflating: /workspace/bert/run_classifier_with_tfhub.py  \n",
            "  inflating: /workspace/bert/run_pretraining.py  \n",
            "  inflating: /workspace/bert/run_squad.py  \n",
            "  inflating: /workspace/bert/sample_text.txt  \n",
            "  inflating: /workspace/bert/scripts/data_download.sh  \n",
            "  inflating: /workspace/bert/scripts/data_download_helper.sh  \n",
            "  inflating: /workspace/bert/scripts/docker/build.sh  \n",
            "  inflating: /workspace/bert/scripts/docker/launch.sh  \n",
            "  inflating: /workspace/bert/scripts/finetune_inference_benchmark.sh  \n",
            "  inflating: /workspace/bert/scripts/finetune_train_benchmark.sh  \n",
            "  inflating: /workspace/bert/scripts/run.sub  \n",
            "  inflating: /workspace/bert/scripts/run_pretraining.sh  \n",
            "  inflating: /workspace/bert/scripts/run_squad.sh  \n",
            "  inflating: /workspace/bert/scripts/run_squad_inference.sh  \n",
            "  inflating: /workspace/bert/scripts/start_pretraining.sh  \n",
            "  inflating: /workspace/bert/tokenization.py  \n",
            "  inflating: /workspace/bert/tokenization_test.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1Dj80t6vruD",
        "colab_type": "text"
      },
      "source": [
        "### BERT Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aEs0P1C_RPIi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e468693-0e47-43ba-c500-235052bb7be2"
      },
      "source": [
        "# Download BERT vocab file\n",
        "!mkdir -p /workspace/bert/config.qa\n",
        "!wget -nc https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt \\\n",
        "    -O /workspace/bert/config.qa/vocab.txt"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘/workspace/bert/config.qa/vocab.txt’ already there; not retrieving.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MO2tAJ5TRRUB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3dbbb411-1fa1-461f-e9ee-03124efbb93e"
      },
      "source": [
        "%%writefile /workspace/bert/config.qa/bert_config.json\n",
        "{\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 1024,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 4096,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"num_attention_heads\": 16,\n",
        "  \"num_hidden_layers\": 24,\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"vocab_size\": 30522\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /workspace/bert/config.qa/bert_config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n62hloeCvruL",
        "colab_type": "text"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVDluZiPvruM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dynamic JSON files based on user inputs\n",
        "def write_input_file(context, qinputs, predict_file):\n",
        "    # Remove quotes and new lines from text for valid JSON\n",
        "    context = context.replace('\"', '').replace('\\n', '')\n",
        "    # Create JSON dict to write\n",
        "    json_dict = {\n",
        "      \"data\": [\n",
        "        {\n",
        "          \"title\": \"BERT QA\",\n",
        "          \"paragraphs\": [\n",
        "            {\n",
        "              \"context\": context,\n",
        "              \"qas\": qinputs\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "    # Write JSON to input file\n",
        "    with open(predict_file, 'w') as json_file:\n",
        "        import json\n",
        "        json.dump(json_dict, json_file, indent=2)\n",
        "    \n",
        "# Display Inference Results as HTML Table\n",
        "def display_results(predict_file, output_prediction_file):\n",
        "    import json\n",
        "    from IPython.display import display, HTML\n",
        "\n",
        "    # Here we show only the prediction results, nbest prediction is also available in the output directory\n",
        "    results = \"\"\n",
        "    with open(predict_file, 'r') as query_file:\n",
        "        queries = json.load(query_file)\n",
        "        input_data = queries[\"data\"]\n",
        "        with open(output_prediction_file, 'r') as result_file:\n",
        "            data = json.load(result_file)\n",
        "            for entry in input_data:\n",
        "                for paragraph in entry[\"paragraphs\"]:\n",
        "                    for qa in paragraph[\"qas\"]:\n",
        "                        results += \"<tr><td>{}</td><td>{}</td><td>{}</td></tr>\".format(qa[\"id\"], qa[\"question\"], data[qa[\"id\"]])\n",
        "\n",
        "    display(HTML(\"<table><tr><th>Id</th><th>Question</th><th>Answer</th></tr>{}</table>\".format(results)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pLdBPppf8AzV"
      },
      "source": [
        "## 3. BERT Inference: Question Answering\n",
        "\n",
        "We can run inference on a fine-tuned BERT model for tasks like Question Answering.\n",
        "\n",
        "Here we use a BERT model fine-tuned on a [SQuaD 2.0 Dataset](https://rajpurkar.github.io/SQuAD-explorer/) which contains 100,000+ question-answer pairs on 500+ articles combined with over 50,000 new, unanswerable questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "J-jHuLNk8AzW"
      },
      "source": [
        "### Paragraph and Queries\n",
        "\n",
        "In this example we will ask our BERT model questions related to the following paragraph:\n",
        "\n",
        "**The Apollo Program**\n",
        "_\"The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two-man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that were necessary for the success of the Apollo missions. Apollo used Saturn family rockets as launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three manned missions in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the Soviet Union in 1975.\"_\n",
        "\n",
        "  \n",
        "---\n",
        "\n",
        "The paragraph and the questions can be easily customized by changing the code below:\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dr_eMAtfSN5R",
        "colab": {}
      },
      "source": [
        "# Create BERT input file with (1) context and (2) questions to be answered based on that context\n",
        "predict_file = '/workspace/bert/config.qa/input.json'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LcOfv3dn8AzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8336cdb-2d58-4b2e-f40f-ab343875341e"
      },
      "source": [
        "%%writefile $predict_file\n",
        "{\"data\": \n",
        " [\n",
        "     {\"title\": \"Project Apollo\",\n",
        "      \"paragraphs\": [\n",
        "          {\"context\":\"The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which accomplished landing the first humans on the Moon from 1969 to 1972. First conceived during Dwight D. Eisenhower's administration as a three-man spacecraft to follow the one-man Project Mercury which put the first Americans in space, Apollo was later dedicated to President John F. Kennedy's national goal of landing a man on the Moon and returning him safely to the Earth by the end of the 1960s, which he proposed in a May 25, 1961, address to Congress. Project Mercury was followed by the two-man Project Gemini. The first manned flight of Apollo was in 1968. Apollo ran from 1961 to 1972, and was supported by the two man Gemini program which ran concurrently with it from 1962 to 1966. Gemini missions developed some of the space travel techniques that were necessary for the success of the Apollo missions. Apollo used Saturn family rockets as launch vehicles. Apollo/Saturn vehicles were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three manned missions in 1973-74, and the Apollo-Soyuz Test Project, a joint Earth orbit mission with the Soviet Union in 1975.\", \n",
        "           \"qas\": [\n",
        "               { \"question\": \"What project put the first Americans into space?\", \n",
        "                 \"id\": \"Q1\"\n",
        "               },\n",
        "               { \"question\": \"What program was created to carry out these projects and missions?\",\n",
        "                 \"id\": \"Q2\"\n",
        "               },\n",
        "               { \"question\": \"What year did the first manned Apollo flight occur?\",\n",
        "                 \"id\": \"Q3\"\n",
        "               },                \n",
        "               { \"question\": \"What President is credited with the notion of putting Americans on the moon?\",\n",
        "                 \"id\": \"Q4\"\n",
        "               },\n",
        "               { \"question\": \"Who did the U.S. collaborate with on an Earth orbit mission in 1975?\",\n",
        "                 \"id\": \"Q5\"\n",
        "               },\n",
        "               { \"question\": \"How long did Project Apollo run?\",\n",
        "                 \"id\": \"Q6\"\n",
        "               },               \n",
        "               { \"question\": \"What program helped develop space travel techniques that Project Apollo used?\",\n",
        "                 \"id\": \"Q7\"\n",
        "               },                \n",
        "               {\"question\": \"What space station supported three manned missions in 1973-1974?\",\n",
        "                 \"id\": \"Q8\"\n",
        "               }\n",
        "]}]}]}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /workspace/bert/config.qa/input.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TTAgKSvG8Azj"
      },
      "source": [
        "To effectively evaluate the speedup of mixed precision try a bigger workload by uncommenting the following lines:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WqYng4Fh6PrK"
      },
      "source": [
        "**TODO: Waiting on model scripts repo to fix Windows newlines in squad_download.sh**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gMJ-3aXN8Azk",
        "colab": {}
      },
      "source": [
        "#!bash /workspace/bert/data/squad/squad_download.sh\n",
        "#predict_file = '/workspace/bert/data/squad/v2.0/dev-v2.0.json'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VNPDdF_f8Azq"
      },
      "source": [
        "## 4. Running Question/Answer Inference\n",
        "\n",
        "To run QA inference we will launch the script run_squad.py with the following parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jNA4ezvR8Azr",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# This specifies the model architecture.\n",
        "bert_config_file = '/workspace/bert/config.qa/bert_config.json'\n",
        "\n",
        "# The vocabulary file that the BERT model was trained on.\n",
        "vocab_file = '/workspace/bert/config.qa/vocab.txt'\n",
        "\n",
        "# Depending on the mixed precision flag we use different fine-tuned model\n",
        "if use_mixed_precision_model:\n",
        "    init_checkpoint = '/workspace/bert/data/finetuned_model_fp16/model.ckpt-8144'\n",
        "else:\n",
        "    init_checkpoint = '/workspace/bert/data/finetuned_model_fp32/model.ckpt-8144'\n",
        "\n",
        "# Create the output directory where all the results are saved.\n",
        "output_dir = '/workspace/bert/results'\n",
        "output_prediction_file = os.path.join(output_dir,'predictions.json')\n",
        "    \n",
        "# Whether to lower case the input - True for uncased models / False for cased models.\n",
        "do_lower_case = True\n",
        "  \n",
        "# Total batch size for predictions\n",
        "predict_batch_size = 8\n",
        "\n",
        "# Whether to run eval on the dev set.\n",
        "do_predict = True\n",
        "\n",
        "# When splitting up a long document into chunks, how much stride to take between chunks.\n",
        "doc_stride = 128\n",
        "\n",
        "# The maximum total input sequence length after WordPiece tokenization.\n",
        "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
        "max_seq_length = 384"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd8b7d9Iy0Eo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4afe9337-eca5-495c-98c9-525b648be64c"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TcC81ooQ8Azt"
      },
      "source": [
        "### 4a. Run Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXH6FVEYzn_v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "outputId": "a1c991f8-75b9-4048-99cb-a361011d6159"
      },
      "source": [
        "!pip install horovod[tensorflow]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting horovod[tensorflow]\n",
            "  Using cached https://files.pythonhosted.org/packages/25/3a/289d100467ae33bce717daa3b285c72e0c82c761c5de37cc61940982c83c/horovod-0.19.5.tar.gz\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from horovod[tensorflow]) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from horovod[tensorflow]) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from horovod[tensorflow]) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from horovod[tensorflow]) (1.12.0)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from horovod[tensorflow]) (1.14.0)\n",
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.2/python3.6 (from horovod[tensorflow]) (1.15.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.4.0->horovod[tensorflow]) (2.20)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (1.30.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (3.2.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (0.9.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.2/python3.6 (from tensorflow->horovod[tensorflow]) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.2/python3.6 (from tensorflow->horovod[tensorflow]) (1.15.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->horovod[tensorflow]) (0.2.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow->horovod[tensorflow]) (47.3.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->horovod[tensorflow]) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow->horovod[tensorflow]) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow->horovod[tensorflow]) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow->horovod[tensorflow]) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow->horovod[tensorflow]) (3.1.0)\n",
            "Building wheels for collected packages: horovod, gast\n",
            "  Building wheel for horovod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for horovod: filename=horovod-0.19.5-cp36-cp36m-linux_x86_64.whl size=16814712 sha256=b095f9ed7ca617c0e26a5dbb31b7034876f3c1caa09091ec9077a976af2b74e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/de/55/40364395c40c35292366a21572320a9b89029df9fb518b7668\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=2ab5a1b69db2afd8e1866f4c54ad74328492fe51ecfe459ca8a313d2e392ecd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built horovod gast\n",
            "Installing collected packages: horovod, gast\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "Successfully installed gast-0.2.2 horovod-0.19.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "No3_W3fd8Azt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "51d8fff5-860f-451a-b114-d418ad7e269a"
      },
      "source": [
        "import horovod.tensorflow as hvd\n",
        "# Ask BERT questions\n",
        "!python /workspace/bert/run_squad.py \\\n",
        "  --bert_config_file=$bert_config_file \\\n",
        "  --vocab_file=$vocab_file \\\n",
        "  --init_checkpoint=$init_checkpoint \\\n",
        "  --output_dir=$output_dir \\\n",
        "  --do_predict=$do_predict \\\n",
        "  --predict_file=$predict_file \\\n",
        "  --predict_batch_size=$predict_batch_size \\\n",
        "  --doc_stride=$doc_stride \\\n",
        "  --max_seq_length=$max_seq_length"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/optimization.py:110: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:162: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1409: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1174: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0630 01:26:15.456149 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:1174: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1174: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0630 01:26:15.456306 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:1174: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0630 01:26:15.456432 140605881927552 module_wrapper.py:139] From /workspace/bert/modeling.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1183: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0630 01:26:15.457169 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:1183: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1199: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0630 01:26:15.530535 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:1199: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0630 01:26:15.530724 140605881927552 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I0630 01:26:16.307311 140605881927552 utils.py:141] NumExpr defaulting to 4 threads.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe0ef3911e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0630 01:26:17.215392 140605881927552 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fe0ef3911e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/workspace/bert/results', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': , '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0ef248400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I0630 01:26:17.216530 140605881927552 estimator.py:212] Using config: {'_model_dir': '/workspace/bert/results', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': , '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe0ef248400>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0630 01:26:17.217167 140605881927552 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0630 01:26:17.217562 140605881927552 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:266: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0630 01:26:17.217749 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:266: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1112: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0630 01:26:17.218805 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:1112: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1354: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0630 01:26:17.256435 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:1354: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "I0630 01:26:17.256598 140605881927552 run_squad.py:1354] ***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 8\n",
            "I0630 01:26:17.256681 140605881927552 run_squad.py:1355]   Num orig examples = 8\n",
            "INFO:tensorflow:  Num split examples = 8\n",
            "I0630 01:26:17.257330 140605881927552 run_squad.py:1356]   Num split examples = 8\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0630 01:26:17.257404 140605881927552 run_squad.py:1357]   Batch size = 8\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:731: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0630 01:26:17.257513 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:731: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /workspace/bert/results, running initialization to predict.\n",
            "I0630 01:26:17.257786 140605881927552 estimator.py:615] Could not find trained model in model_dir: /workspace/bert/results, running initialization to predict.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0630 01:26:17.292456 140605881927552 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:776: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0630 01:26:17.311208 140605881927552 deprecation.py:323] From /workspace/bert/run_squad.py:776: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0630 01:26:17.311437 140605881927552 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0630 01:26:17.362251 140605881927552 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:750: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0630 01:26:17.451747 140605881927552 deprecation.py:323] From /workspace/bert/run_squad.py:750: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0630 01:26:17.464431 140605881927552 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0630 01:26:17.464589 140605881927552 tpu_estimator.py:3124] Running infer on CPU\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0630 01:26:17.474518 140605881927552 module_wrapper.py:139] From /workspace/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:413: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0630 01:26:17.475714 140605881927552 module_wrapper.py:139] From /workspace/bert/modeling.py:413: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:494: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0630 01:26:17.499996 140605881927552 module_wrapper.py:139] From /workspace/bert/modeling.py:494: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:675: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0630 01:26:17.549618 140605881927552 deprecation.py:323] From /workspace/bert/modeling.py:675: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0630 01:26:17.550658 140605881927552 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:655: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0630 01:26:20.645684 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:655: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:670: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0630 01:26:20.650635 140605881927552 module_wrapper.py:139] From /workspace/bert/run_squad.py:670: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0630 01:26:21.697369 140605881927552 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0630 01:26:21.940951 140605881927552 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0630 01:26:22.423916 140605881927552 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-30 01:26:22.442826: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-06-30 01:26:22.443360: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x217ad80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-30 01:26:22.443397: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-30 01:26:22.448396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-30 01:26:22.575340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:26:22.576138: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x217af40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-30 01:26:22.576179: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-06-30 01:26:22.576434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:26:22.577056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-30 01:26:22.577430: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-30 01:26:22.802506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-30 01:26:22.932540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-30 01:26:22.952410: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-30 01:26:23.227738: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-30 01:26:23.248245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-30 01:26:23.746531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-30 01:26:23.746804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:26:23.747545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:26:23.748046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-06-30 01:26:23.754496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-30 01:26:23.755858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-30 01:26:23.755902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-06-30 01:26:23.755911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-06-30 01:26:23.756328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:26:23.757045: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:26:23.757621: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-30 01:26:23.757666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0630 01:26:31.500057 140605881927552 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0630 01:26:31.588577 140605881927552 session_manager.py:502] Done running local_init_op.\n",
            "2020-06-30 01:26:32.805464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:Processing example: 0\n",
            "I0630 01:26:34.729495 140605881927552 run_squad.py:1373] Processing example: 0\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0630 01:26:34.825925 140605881927552 error_handling.py:101] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0630 01:26:34.826132 140605881927552 error_handling.py:101] prediction_loop marked as finished\n",
            "INFO:tensorflow:-----------------------------\n",
            "I0630 01:26:34.826223 140605881927552 run_squad.py:1388] -----------------------------\n",
            "INFO:tensorflow:0 Total Inference Time = 17.57 Inference Time W/O start up overhead = 2.62 Sentences processed = 8\n",
            "I0630 01:26:34.826278 140605881927552 run_squad.py:1391] 0 Total Inference Time = 17.57 Inference Time W/O start up overhead = 2.62 Sentences processed = 8\n",
            "INFO:tensorflow:0 Inference Performance = 3.0580 sentences/sec\n",
            "I0630 01:26:34.826339 140605881927552 run_squad.py:1392] 0 Inference Performance = 3.0580 sentences/sec\n",
            "INFO:tensorflow:-----------------------------\n",
            "I0630 01:26:34.826384 140605881927552 run_squad.py:1393] -----------------------------\n",
            "INFO:tensorflow:Writing predictions to: /workspace/bert/results/predictions.json\n",
            "I0630 01:26:34.826460 140605881927552 run_squad.py:792] Writing predictions to: /workspace/bert/results/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: /workspace/bert/results/nbest_predictions.json\n",
            "I0630 01:26:34.826505 140605881927552 run_squad.py:793] Writing nbest to: /workspace/bert/results/nbest_predictions.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ELf0wtQ08Azw"
      },
      "source": [
        "### 4b. Display Results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lZ0OZclQ8Azw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "91704a2d-8b01-4e02-cff3-1f6f2f2ee038"
      },
      "source": [
        "display_results(predict_file, output_prediction_file)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table><tr><th>Id</th><th>Question</th><th>Answer</th></tr><tr><td>Q1</td><td>What project put the first Americans into space?</td><td>Project Mercury</td></tr><tr><td>Q2</td><td>What program was created to carry out these projects and missions?</td><td>The Apollo program</td></tr><tr><td>Q3</td><td>What year did the first manned Apollo flight occur?</td><td>1968</td></tr><tr><td>Q4</td><td>What President is credited with the notion of putting Americans on the moon?</td><td>John F. Kennedy</td></tr><tr><td>Q5</td><td>Who did the U.S. collaborate with on an Earth orbit mission in 1975?</td><td>Soviet Union</td></tr><tr><td>Q6</td><td>How long did Project Apollo run?</td><td>1961 to 1972</td></tr><tr><td>Q7</td><td>What program helped develop space travel techniques that Project Apollo used?</td><td>Gemini missions</td></tr><tr><td>Q8</td><td>What space station supported three manned missions in 1973-1974?</td><td>Skylab</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NH0Umn_e6Jsz"
      },
      "source": [
        "<details>\n",
        "  <summary><b>Click to reveal expected answers to the questions above</b></summary>\n",
        "  \n",
        "| Id | Question | Answer |\n",
        "|----|----------|--------|\n",
        "| Q1 | What project put the first Americans into space? | Project Mercury |\n",
        "| Q2 | What program was created to carry out these projects and missions? | The Apollo program |\n",
        "| Q3 | What year did the first manned Apollo flight occur? | 1968 |\n",
        "| Q4 | What President is credited with the notion of putting Americans on the moon?\t | John F. Kennedy |\n",
        "| Q5 | Who did the U.S. collaborate with on an Earth orbit mission in 1975? | Soviet Union |\n",
        "| Q6 | How long did Project Apollo run? | 1961 to 1972 |\n",
        "| Q7 | What program helped develop space travel techniques that Project Apollo used? | Gemini missions |\n",
        "| Q8 | What space station supported three manned missions in 1973-1974? | Skylab |\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sQ8EfbPm8Azz"
      },
      "source": [
        "## 5. Custom Inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OHWl7yus8Azz"
      },
      "source": [
        "Now that you are familiar with running QA Inference on BERT, you may want to try\n",
        "your own paragraphs and queries.\n",
        "\n",
        "\n",
        "1. Copy and paste your context from Wikipedia, news articles, etc. when prompted below\n",
        "2. Enter questions based on the context when prompted below.\n",
        "3. Run the inference script\n",
        "4. Display the inference results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mvnB1JUpWV_a",
        "colab": {}
      },
      "source": [
        "predict_file = '/workspace/bert/config.qa/custom_input.json'\n",
        "num_questions = 3           # You can configure this number"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ryd1akIpBaKz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "788b58c3-3c33-460f-fd0f-286b767aebf9"
      },
      "source": [
        "# Create your own context to ask questions about.\n",
        "context = input(\"Paste your context here: \")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Paste your context here: Alan Mathison Turing OBE FRS (/ˈtjʊərɪŋ/; 23 June 1912 – 7 June 1954) was an English[6] mathematician, computer scientist, logician, cryptanalyst, philosopher and theoretical biologist.[7] Turing was highly influential in the development of theoretical computer science, providing a formalisation of the concepts of algorithm and computation with the Turing machine, which can be considered a model of a general-purpose computer.[8][9][10] Turing is widely considered to be the father of theoretical computer science and artificial intelligence.[11] Despite these accomplishments, he was not fully recognised in his home country during his lifetime, due to his homosexuality, and because much of his work was covered by the Official Secrets Act.  During the Second World War, Turing worked for the Government Code and Cypher School (GC&CS) at Bletchley Park, Britain's codebreaking centre that produced Ultra intelligence. For a time he led Hut 8, the section that was responsible for German naval cryptanalysis. Here, he devised a number of techniques for speeding the breaking of German ciphers, including improvements to the pre-war Polish bombe method, an electromechanical machine that could find settings for the Enigma machine.  Turing played a pivotal role in cracking intercepted coded messages that enabled the Allies to defeat the Nazis in many crucial engagements, including the Battle of the Atlantic, and in so doing helped win the war.[12][13] Due to the problems of counterfactual history, it's hard to estimate what effect Ultra intelligence had on the war,[14] but at the upper end it has been estimated that this work shortened the war in Europe by more than two years and saved over 14 million lives.[12]  After the war, Turing worked at the National Physical Laboratory, where he designed the Automatic Computing Engine, which was one of the first designs for a stored-program computer. In 1948, Turing joined Max Newman's Computing Machine Laboratory at the Victoria University of Manchester, where he helped develop the Manchester computers[15] and became interested in mathematical biology. He wrote a paper on the chemical basis of morphogenesis[1] and predicted oscillating chemical reactions such as the Belousov–Zhabotinsky reaction, first observed in the 1960s.  Turing was prosecuted in 1952 for homosexual acts; the Labouchere Amendment of 1885 had mandated that \"gross indecency\" was a criminal offence in the UK. He accepted chemical castration treatment, with DES, as an alternative to prison. Turing died in 1954, 16 days before his 42nd birthday, from cyanide poisoning. An inquest determined his death as a suicide, but it has been noted that the known evidence is also consistent with accidental poisoning.  In 2009, following an Internet campaign, British Prime Minister Gordon Brown made an official public apology on behalf of the British government for \"the appalling way he was treated\". Queen Elizabeth II granted Turing a posthumous pardon in 2013. The Alan Turing law is now an informal term for a 2017 law in the United Kingdom that retroactively pardoned men cautioned or convicted under historical legislation that outlawed homosexual acts.[16]  On 15 July 2019 the Bank of England announced that Turing would be depicted on the United Kingdom's new £50 note.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fEalqfQXnZDT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "4bd6a158-b1da-436b-a1bb-088ffb78ccb0"
      },
      "source": [
        "# Get questions from user input\n",
        "questions = [input(\"Question {}/{}: \".format(i+1, num_questions)) for i in range(num_questions)]\n",
        "# Format questions and write to JSON input file\n",
        "qinputs = [{ \"question\":q, \"id\":\"Q{}\".format(i+1)} for i,q in enumerate(questions)]\n",
        "write_input_file(context, qinputs, predict_file)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question 1/3: Who is Alan Turing?\n",
            "Question 2/3: What did he do?\n",
            "Question 3/3: Where did he work?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X_RbzPEGWeWE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "90c9a69e-b52f-467a-dabf-7733b88aa13a"
      },
      "source": [
        "# Ask BERT questions\n",
        "!python /workspace/bert/run_squad.py \\\n",
        "  --bert_config_file=$bert_config_file \\\n",
        "  --vocab_file=$vocab_file \\\n",
        "  --init_checkpoint=$init_checkpoint \\\n",
        "  --output_dir=$output_dir \\\n",
        "  --do_predict=$do_predict \\\n",
        "  --predict_file=$predict_file \\\n",
        "  --predict_batch_size=$predict_batch_size \\\n",
        "  --doc_stride=$doc_stride \\\n",
        "  --max_seq_length=$max_seq_length"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /workspace/bert/optimization.py:110: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:163: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/horovod/tensorflow/__init__.py:189: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:162: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1409: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1174: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "W0630 01:33:02.349607 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:1174: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1174: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "W0630 01:33:02.349749 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:1174: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0630 01:33:02.349860 140258253739904 module_wrapper.py:139] From /workspace/bert/modeling.py:94: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1183: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0630 01:33:02.350565 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:1183: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1199: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0630 01:33:02.423591 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:1199: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W0630 01:33:02.423774 140258253739904 lazy_loader.py:50] \n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "I0630 01:33:02.853027 140258253739904 utils.py:141] NumExpr defaulting to 4 threads.\n",
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8ffef901e0>) includes params argument, but params are not passed to Estimator.\n",
            "W0630 01:33:03.157716 140258253739904 estimator.py:1994] Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f8ffef901e0>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/workspace/bert/results', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': , '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8fffb4e518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "I0630 01:33:03.158641 140258253739904 estimator.py:212] Using config: {'_model_dir': '/workspace/bert/results', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': , '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f8fffb4e518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_cluster': None}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n",
            "I0630 01:33:03.159237 140258253739904 tpu_context.py:220] _TPUContext: eval_on_tpu True\n",
            "WARNING:tensorflow:eval_on_tpu ignored because use_tpu is False.\n",
            "W0630 01:33:03.159632 140258253739904 tpu_context.py:222] eval_on_tpu ignored because use_tpu is False.\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:266: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0630 01:33:03.159804 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:266: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1112: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "W0630 01:33:03.161627 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:1112: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:1354: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0630 01:33:03.205703 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:1354: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:***** Running predictions *****\n",
            "I0630 01:33:03.205858 140258253739904 run_squad.py:1354] ***** Running predictions *****\n",
            "INFO:tensorflow:  Num orig examples = 3\n",
            "I0630 01:33:03.206009 140258253739904 run_squad.py:1355]   Num orig examples = 3\n",
            "INFO:tensorflow:  Num split examples = 12\n",
            "I0630 01:33:03.206447 140258253739904 run_squad.py:1356]   Num split examples = 12\n",
            "INFO:tensorflow:  Batch size = 8\n",
            "I0630 01:33:03.206544 140258253739904 run_squad.py:1357]   Batch size = 8\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:731: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0630 01:33:03.206685 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:731: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /workspace/bert/results, running initialization to predict.\n",
            "I0630 01:33:03.207021 140258253739904 estimator.py:615] Could not find trained model in model_dir: /workspace/bert/results, running initialization to predict.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "W0630 01:33:03.211784 140258253739904 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:776: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "W0630 01:33:03.229813 140258253739904 deprecation.py:323] From /workspace/bert/run_squad.py:776: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "W0630 01:33:03.230016 140258253739904 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/data/python/ops/batching.py:276: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "W0630 01:33:03.279605 140258253739904 module_wrapper.py:139] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:750: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0630 01:33:03.363421 140258253739904 deprecation.py:323] From /workspace/bert/run_squad.py:750: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0630 01:33:03.377237 140258253739904 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:Running infer on CPU\n",
            "I0630 01:33:03.377469 140258253739904 tpu_estimator.py:3124] Running infer on CPU\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0630 01:33:03.380284 140258253739904 module_wrapper.py:139] From /workspace/bert/modeling.py:175: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:413: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "W0630 01:33:03.381502 140258253739904 module_wrapper.py:139] From /workspace/bert/modeling.py:413: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:494: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "W0630 01:33:03.407097 140258253739904 module_wrapper.py:139] From /workspace/bert/modeling.py:494: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/modeling.py:675: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "W0630 01:33:03.456699 140258253739904 deprecation.py:323] From /workspace/bert/modeling.py:675: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0630 01:33:03.457988 140258253739904 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:655: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "W0630 01:33:06.593495 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:655: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /workspace/bert/run_squad.py:670: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "W0630 01:33:06.598105 140258253739904 module_wrapper.py:139] From /workspace/bert/run_squad.py:670: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0630 01:33:07.637377 140258253739904 estimator.py:1150] Done calling model_fn.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0630 01:33:07.870377 140258253739904 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0630 01:33:08.364064 140258253739904 monitored_session.py:240] Graph was finalized.\n",
            "2020-06-30 01:33:08.369106: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-06-30 01:33:08.369363: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3026d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-30 01:33:08.369394: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-06-30 01:33:08.371242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-06-30 01:33:08.474797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:33:08.475664: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3026f40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-06-30 01:33:08.475698: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-06-30 01:33:08.475905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:33:08.476483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-06-30 01:33:08.476766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-30 01:33:08.478252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-06-30 01:33:08.479719: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-06-30 01:33:08.480069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-06-30 01:33:08.481617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-06-30 01:33:08.482310: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-06-30 01:33:08.485334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-06-30 01:33:08.485467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:33:08.486139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:33:08.486649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-06-30 01:33:08.486697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-06-30 01:33:08.487837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-06-30 01:33:08.487862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-06-30 01:33:08.487879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-06-30 01:33:08.488010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:33:08.488750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-06-30 01:33:08.489244: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-06-30 01:33:08.489277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0630 01:33:10.668742 140258253739904 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0630 01:33:10.753475 140258253739904 session_manager.py:502] Done running local_init_op.\n",
            "2020-06-30 01:33:11.926629: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:Processing example: 0\n",
            "I0630 01:33:12.599485 140258253739904 run_squad.py:1373] Processing example: 0\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0630 01:33:12.883350 140258253739904 error_handling.py:101] prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "I0630 01:33:12.883586 140258253739904 error_handling.py:101] prediction_loop marked as finished\n",
            "INFO:tensorflow:-----------------------------\n",
            "I0630 01:33:12.883677 140258253739904 run_squad.py:1388] -----------------------------\n",
            "INFO:tensorflow:0 Total Inference Time = 9.68 Inference Time W/O start up overhead = 1.55 Sentences processed = 16\n",
            "I0630 01:33:12.883730 140258253739904 run_squad.py:1391] 0 Total Inference Time = 9.68 Inference Time W/O start up overhead = 1.55 Sentences processed = 16\n",
            "INFO:tensorflow:0 Inference Performance = 10.3496 sentences/sec\n",
            "I0630 01:33:12.883790 140258253739904 run_squad.py:1392] 0 Inference Performance = 10.3496 sentences/sec\n",
            "INFO:tensorflow:-----------------------------\n",
            "I0630 01:33:12.883837 140258253739904 run_squad.py:1393] -----------------------------\n",
            "INFO:tensorflow:Writing predictions to: /workspace/bert/results/predictions.json\n",
            "I0630 01:33:12.883946 140258253739904 run_squad.py:792] Writing predictions to: /workspace/bert/results/predictions.json\n",
            "INFO:tensorflow:Writing nbest to: /workspace/bert/results/nbest_predictions.json\n",
            "I0630 01:33:12.884004 140258253739904 run_squad.py:793] Writing nbest to: /workspace/bert/results/nbest_predictions.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aMnxQZb_WiUN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        },
        "outputId": "2099ad4b-6e47-40dd-88e3-f610a07307c9"
      },
      "source": [
        "display_results(predict_file, output_prediction_file)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table><tr><th>Id</th><th>Question</th><th>Answer</th></tr><tr><td>Q1</td><td>Who is Alan Turing?</td><td>father of theoretical computer science and artificial intelligence</td></tr><tr><td>Q2</td><td>What did he do?</td><td>designed the Automatic Computing Engine</td></tr><tr><td>Q3</td><td>Where did he work?</td><td>Government Code and Cypher School</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}