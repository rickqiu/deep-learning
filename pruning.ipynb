{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNuKtAnpY87v/Su1OAG8UM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickqiu/deep-learning/blob/master/pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LK9OjPQBRX3c"
      },
      "source": [
        " !pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AD8FW9f9zJr6"
      },
      "source": [
        "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\r\n",
        "#\r\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n",
        "# you may not use this file except in compliance with the License.\r\n",
        "# You may obtain a copy of the License at\r\n",
        "#\r\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\r\n",
        "#\r\n",
        "# Unless required by applicable law or agreed to in writing, software\r\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n",
        "# See the License for the specific language governing permissions and\r\n",
        "# limitations under the License.\r\n",
        "# ==============================================================================\r\n",
        "# pylint: disable=missing-docstring\r\n",
        "\"\"\"Train a simple convnet on the MNIST dataset.\"\"\"\r\n",
        "from __future__ import print_function\r\n",
        "\r\n",
        "from absl import app as absl_app\r\n",
        "from absl import flags\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune\r\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\r\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\r\n",
        "\r\n",
        "ConstantSparsity = pruning_schedule.ConstantSparsity\r\n",
        "keras = tf.keras\r\n",
        "l = keras.layers\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_classes = 10\r\n",
        "epochs = 12\r\n",
        " \r\n",
        "def build_sequential_model(input_shape):\r\n",
        "  return tf.keras.Sequential([\r\n",
        "      l.Conv2D(\r\n",
        "          32, 5, padding='same', activation='relu', input_shape=input_shape),\r\n",
        "      l.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n",
        "      l.BatchNormalization(),\r\n",
        "      l.Conv2D(64, 5, padding='same', activation='relu'),\r\n",
        "      l.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n",
        "      l.Flatten(),\r\n",
        "      l.Dense(1024, activation='relu'),\r\n",
        "      l.Dropout(0.4),\r\n",
        "      l.Dense(num_classes, activation='softmax')\r\n",
        "  ])\r\n",
        "\r\n",
        "\r\n",
        "def build_functional_model(input_shape):\r\n",
        "  inp = tf.keras.Input(shape=input_shape)\r\n",
        "  x = l.Conv2D(32, 5, padding='same', activation='relu')(inp)\r\n",
        "  x = l.MaxPooling2D((2, 2), (2, 2), padding='same')(x)\r\n",
        "  x = l.BatchNormalization()(x)\r\n",
        "  x = l.Conv2D(64, 5, padding='same', activation='relu')(x)\r\n",
        "  x = l.MaxPooling2D((2, 2), (2, 2), padding='same')(x)\r\n",
        "  x = l.Flatten()(x)\r\n",
        "  x = l.Dense(1024, activation='relu')(x)\r\n",
        "  x = l.Dropout(0.4)(x)\r\n",
        "  out = l.Dense(num_classes, activation='softmax')(x)\r\n",
        "\r\n",
        "  return tf.keras.models.Model([inp], [out])\r\n",
        "\r\n",
        "\r\n",
        "def build_layerwise_model(input_shape, **pruning_params):\r\n",
        "  return tf.keras.Sequential([\r\n",
        "      prune.prune_low_magnitude(\r\n",
        "          l.Conv2D(32, 5, padding='same', activation='relu'),\r\n",
        "          input_shape=input_shape,\r\n",
        "          **pruning_params),\r\n",
        "      l.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n",
        "      l.BatchNormalization(),\r\n",
        "      prune.prune_low_magnitude(\r\n",
        "          l.Conv2D(64, 5, padding='same', activation='relu'), **pruning_params),\r\n",
        "      l.MaxPooling2D((2, 2), (2, 2), padding='same'),\r\n",
        "      l.Flatten(),\r\n",
        "      prune.prune_low_magnitude(\r\n",
        "          l.Dense(1024, activation='relu'), **pruning_params),\r\n",
        "      l.Dropout(0.4),\r\n",
        "      prune.prune_low_magnitude(\r\n",
        "          l.Dense(num_classes, activation='softmax'), **pruning_params)\r\n",
        "  ])\r\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uOqU7CMzO24"
      },
      "source": [
        "def train_and_save(models, x_train, y_train, x_test, y_test):\r\n",
        "  for model in models:\r\n",
        "    model.compile(\r\n",
        "        loss=tf.keras.losses.categorical_crossentropy,\r\n",
        "        optimizer='adam',\r\n",
        "        metrics=['accuracy'])\r\n",
        "\r\n",
        "    # Print the model summary.\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    # Add a pruning step callback to peg the pruning step to the optimizer's\r\n",
        "    # step. Also add a callback to add pruning summaries to tensorboard\r\n",
        "    callbacks = [\r\n",
        "        pruning_callbacks.UpdatePruningStep(),\r\n",
        "        pruning_callbacks.PruningSummaries(log_dir='/content/log_p/')\r\n",
        "    ]\r\n",
        "\r\n",
        "    model.fit(\r\n",
        "        x_train,\r\n",
        "        y_train,\r\n",
        "        batch_size=batch_size,\r\n",
        "        epochs=epochs,\r\n",
        "        verbose=1,\r\n",
        "        callbacks=callbacks,\r\n",
        "        validation_data=(x_test, y_test))\r\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "    print('Test loss:', score[0])\r\n",
        "    print('Test accuracy:', score[1])\r\n",
        "\r\n",
        "    # Export and import the model. Check that accuracy persists.\r\n",
        "    saved_model_dir = '/content/saved_model/'\r\n",
        "    print('Saving model to: ', saved_model_dir)\r\n",
        "    tf.keras.models.save_model(model, saved_model_dir, save_format='tf')\r\n",
        "    print('Loading model from: ', saved_model_dir)\r\n",
        "    loaded_model = tf.keras.models.load_model(saved_model_dir)\r\n",
        "\r\n",
        "    score = loaded_model.evaluate(x_test, y_test, verbose=0)\r\n",
        "    print('Test loss:', score[0])\r\n",
        "    print('Test accuracy:', score[1])\r\n",
        "\r\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu-cPwGrz7lX",
        "outputId": "253d6228-fc7b-48f6-b728-b6b42d08728e"
      },
      "source": [
        "img_rows, img_cols = 28, 28\r\n",
        "\r\n",
        "# the data, shuffled and split between train and test sets\r\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n",
        "\r\n",
        "if tf.keras.backend.image_data_format() == 'channels_first':\r\n",
        "  x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n",
        "  x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n",
        "  input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "  x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n",
        "  x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n",
        "  input_shape = (img_rows, img_cols, 1)\r\n",
        "\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "x_train /= 255\r\n",
        "x_test /= 255\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "\r\n",
        "# convert class vectors to binary class matrices\r\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "pruning_params = {\r\n",
        "    'pruning_schedule': ConstantSparsity(0.75, begin_step=2000, frequency=100)\r\n",
        "}\r\n",
        "\r\n",
        "layerwise_model = build_layerwise_model(input_shape, **pruning_params)\r\n",
        "sequential_model = build_sequential_model(input_shape)\r\n",
        "sequential_model = prune.prune_low_magnitude(sequential_model, **pruning_params)\r\n",
        "functional_model = build_functional_model(input_shape)\r\n",
        "functional_model = prune.prune_low_magnitude(functional_model, **pruning_params)\r\n",
        "\r\n",
        "models = [layerwise_model, sequential_model, functional_model]\r\n",
        "train_and_save(models, x_train, y_train, x_test, y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:2281: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_3 (None, 28, 28, 32)        1634      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_15 (Batc (None, 14, 14, 32)        128       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_3 (None, 14, 14, 64)        102466    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_15 (Flatten)         (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_30 (None, 1024)              6423554   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_31 (None, 10)                20492     \n",
            "=================================================================\n",
            "Total params: 6,548,274\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 3,273,576\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 185s 389ms/step - loss: 0.4816 - accuracy: 0.8794 - val_loss: 0.1553 - val_accuracy: 0.9856\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 178s 379ms/step - loss: 0.0449 - accuracy: 0.9853 - val_loss: 0.0344 - val_accuracy: 0.9887\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 174s 372ms/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.0260 - val_accuracy: 0.9905\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 178s 380ms/step - loss: 0.0257 - accuracy: 0.9923 - val_loss: 0.0286 - val_accuracy: 0.9906\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 182s 388ms/step - loss: 0.0323 - accuracy: 0.9915 - val_loss: 0.0249 - val_accuracy: 0.9920\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 178s 379ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0216 - val_accuracy: 0.9932\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 175s 372ms/step - loss: 0.0125 - accuracy: 0.9957 - val_loss: 0.0223 - val_accuracy: 0.9928\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 176s 376ms/step - loss: 0.0081 - accuracy: 0.9978 - val_loss: 0.0240 - val_accuracy: 0.9926\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 174s 370ms/step - loss: 0.0065 - accuracy: 0.9982 - val_loss: 0.0247 - val_accuracy: 0.9926\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 173s 368ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0359 - val_accuracy: 0.9887\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 172s 366ms/step - loss: 0.0046 - accuracy: 0.9983 - val_loss: 0.0281 - val_accuracy: 0.9921\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 172s 366ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0291 - val_accuracy: 0.9916\n",
            "Test loss: 0.029110247269272804\n",
            "Test accuracy: 0.991599977016449\n",
            "Saving model to:  /content/saved_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0303 21:30:48.750472 140323953530752 save.py:241] Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, dense_30_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n",
            "W0303 21:30:48.845887 140323953530752 save.py:241] Found untraced functions such as conv2d_30_layer_call_and_return_conditional_losses, conv2d_30_layer_call_fn, conv2d_31_layer_call_and_return_conditional_losses, conv2d_31_layer_call_fn, dense_30_layer_call_and_return_conditional_losses while saving (showing 5 of 20). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0303 21:30:49.390856 140323953530752 builder_impl.py:775] Assets written to: /content/saved_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading model from:  /content/saved_model/\n",
            "Test loss: 0.029110318049788475\n",
            "Test accuracy: 0.991599977016449\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_conv2d_3 (None, 28, 28, 32)        1634      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 14, 14, 32)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 14, 14, 32)        129       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_3 (None, 14, 14, 64)        102466    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 7, 7, 64)          1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 3136)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_32 (None, 1024)              6423554   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dropout_ (None, 1024)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_33 (None, 10)                20492     \n",
            "=================================================================\n",
            "Total params: 6,548,279\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 3,273,581\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 175s 368ms/step - loss: 0.4759 - accuracy: 0.8839 - val_loss: 0.1151 - val_accuracy: 0.9862\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 174s 370ms/step - loss: 0.0470 - accuracy: 0.9850 - val_loss: 0.0282 - val_accuracy: 0.9904\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 171s 365ms/step - loss: 0.0321 - accuracy: 0.9902 - val_loss: 0.0247 - val_accuracy: 0.9910\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 172s 366ms/step - loss: 0.0220 - accuracy: 0.9929 - val_loss: 0.0240 - val_accuracy: 0.9923\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 172s 368ms/step - loss: 0.0307 - accuracy: 0.9908 - val_loss: 0.0203 - val_accuracy: 0.9935\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 175s 372ms/step - loss: 0.0163 - accuracy: 0.9947 - val_loss: 0.0223 - val_accuracy: 0.9929\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 174s 371ms/step - loss: 0.0135 - accuracy: 0.9960 - val_loss: 0.0191 - val_accuracy: 0.9941\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 176s 375ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0214 - val_accuracy: 0.9935\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 176s 375ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.0242 - val_accuracy: 0.9930\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 174s 372ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0275 - val_accuracy: 0.9927\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 175s 374ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0249 - val_accuracy: 0.9934\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 176s 375ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.0253 - val_accuracy: 0.9926\n",
            "Test loss: 0.025313185527920723\n",
            "Test accuracy: 0.9926000237464905\n",
            "Saving model to:  /content/saved_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0303 22:05:59.989152 140323953530752 save.py:241] Found untraced functions such as conv2d_32_layer_call_and_return_conditional_losses, conv2d_32_layer_call_fn, conv2d_33_layer_call_and_return_conditional_losses, conv2d_33_layer_call_fn, flatten_16_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "W0303 22:06:00.091035 140323953530752 save.py:241] Found untraced functions such as conv2d_32_layer_call_and_return_conditional_losses, conv2d_32_layer_call_fn, conv2d_33_layer_call_and_return_conditional_losses, conv2d_33_layer_call_fn, flatten_16_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0303 22:06:00.694692 140323953530752 builder_impl.py:775] Assets written to: /content/saved_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading model from:  /content/saved_model/\n",
            "Test loss: 0.025313278660178185\n",
            "Test accuracy: 0.9926000237464905\n",
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_3 (None, 28, 28, 32)        1634      \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 14, 14, 32)        1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_batch_no (None, 14, 14, 32)        129       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_conv2d_3 (None, 14, 14, 64)        102466    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_max_pool (None, 7, 7, 64)          1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_flatten_ (None, 3136)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_34 (None, 1024)              6423554   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dropout_ (None, 1024)              1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense_35 (None, 10)                20492     \n",
            "=================================================================\n",
            "Total params: 6,548,279\n",
            "Trainable params: 3,274,698\n",
            "Non-trainable params: 3,273,581\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 177s 373ms/step - loss: 0.6661 - accuracy: 0.8448 - val_loss: 0.0961 - val_accuracy: 0.9836\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 175s 373ms/step - loss: 0.0535 - accuracy: 0.9839 - val_loss: 0.0318 - val_accuracy: 0.9889\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 177s 377ms/step - loss: 0.0349 - accuracy: 0.9890 - val_loss: 0.0253 - val_accuracy: 0.9913\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 177s 376ms/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.0239 - val_accuracy: 0.9918\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 178s 379ms/step - loss: 0.0350 - accuracy: 0.9901 - val_loss: 0.0235 - val_accuracy: 0.9922\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 178s 380ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.0193 - val_accuracy: 0.9942\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 176s 375ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0238 - val_accuracy: 0.9928\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 176s 376ms/step - loss: 0.0128 - accuracy: 0.9959 - val_loss: 0.0184 - val_accuracy: 0.9944\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 175s 374ms/step - loss: 0.0092 - accuracy: 0.9972 - val_loss: 0.0219 - val_accuracy: 0.9931\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 175s 374ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0197 - val_accuracy: 0.9936\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 175s 374ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 0.0241 - val_accuracy: 0.9930\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 175s 374ms/step - loss: 0.0055 - accuracy: 0.9983 - val_loss: 0.0222 - val_accuracy: 0.9929\n",
            "Test loss: 0.02221725694835186\n",
            "Test accuracy: 0.992900013923645\n",
            "Saving model to:  /content/saved_model/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0303 22:41:37.122542 140323953530752 save.py:241] Found untraced functions such as conv2d_34_layer_call_and_return_conditional_losses, conv2d_34_layer_call_fn, conv2d_35_layer_call_and_return_conditional_losses, conv2d_35_layer_call_fn, flatten_17_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "W0303 22:41:37.227815 140323953530752 save.py:241] Found untraced functions such as conv2d_34_layer_call_and_return_conditional_losses, conv2d_34_layer_call_fn, conv2d_35_layer_call_and_return_conditional_losses, conv2d_35_layer_call_fn, flatten_17_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0303 22:41:37.872245 140323953530752 builder_impl.py:775] Assets written to: /content/saved_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading model from:  /content/saved_model/\n",
            "Test loss: 0.022185372188687325\n",
            "Test accuracy: 0.992900013923645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykBqGnA80I3K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}