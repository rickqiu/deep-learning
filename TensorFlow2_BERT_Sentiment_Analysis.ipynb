{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TensorFlow2_BERT_Sentiment_Analysis.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickqiu/deep-learning/blob/master/TensorFlow2_BERT_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o2nRY4GyKWqL"
      },
      "source": [
        "# TensorFlow 2 - BERT: Movie Review Sentiment Analysis\n",
        "\n",
        "$BERT$ stands for Bidirectional Encoder Representations from Transformers. A pre-trained BERT model can be fine tuned to create state-of-the-art models for a wide range of NLP tasks such as question answering, sentiment analysis and named entity recognition. $BERT_{BASE}$ has total parameters of 110M (L=12, H=768, A=12, Total Parameters=110M) and $BERT_{LARGE}$ has 340M (L=24, H=1024, A=16, Total Parameters=340M) (Devlin et al, 2019, [BERT paper link](https://arxiv.org/pdf/1810.04805.pdf)).\n",
        "\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "IMDB dataset has 50K movie reviews for natural language processing.\n",
        "Please download the dataset from [Kaggle link](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews).\n",
        "\n",
        "**Problem**\n",
        "\n",
        "A review in the IMDB dataset is either positive or negative. Therefore, the NLP movie review sentiment analysis task is a supervised learning binary classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Bvh3ECwPcRI6",
        "colab": {}
      },
      "source": [
        "# Install the required package\n",
        "!pip install bert-for-tf2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dotZjUvecRI8",
        "outputId": "cd2abfa6-298a-44d9-f24d-5aff1a5367d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Import modules\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bert\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import  Model\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)\n",
        "pd.set_option('display.max_colwidth',1000)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.2.0\n",
            "Hub version:  0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-uH1zw2Pa13m"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W379xRxlMbtb",
        "colab": {}
      },
      "source": [
        "# Read the IMDB Dataset.csv into Pandas dataframe\n",
        "df=pd.read_csv('IMDB Dataset.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5GbNMjbS_b8J",
        "outputId": "992f066e-1cc8-4b0e-a6f2-4d58da203d19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# Take a peek at the dataset\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.&lt;br /&gt;&lt;br /&gt;The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.&lt;br /&gt;&lt;br /&gt;It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.&lt;br /&gt;&lt;br /&gt;I would say the main appeal of the show is due to the...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. &lt;br /&gt;&lt;br /&gt;The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. &lt;br /&gt;&lt;br /&gt;The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.&lt;br /&gt;&lt;br /&gt;This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.&lt;br /&gt;&lt;br /&gt;This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet &amp; his parents are fighting all the time.&lt;br /&gt;&lt;br /&gt;This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.&lt;br /&gt;&lt;br /&gt;OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing &amp; arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.&lt;br /&gt;&lt;br /&gt;3 out of 10 just for the well playing parents &amp; descent dialogs. As for the shots with Jake: just ignore them.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. &lt;br /&gt;&lt;br /&gt;This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.&lt;br /&gt;&lt;br /&gt;The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case wi...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    review sentiment\n",
              "0  One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the...  positive\n",
              "1   A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.  positive\n",
              "2                                                                           I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.  positive\n",
              "3                                                                                                                                                                                                                                                             Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is a visually stunning film to watch. Mr. Mattei offers us a vivid portrait about human relations. This is a movie that seems to be telling us what money, power and success do to people in the different situations we encounter. <br /><br />This being a variation on the Arthur Schnitzler's play about the same theme, the director transfers the action to the present time New York where all these different characters meet and connect. Each one is connected in one way, or another to the next person, but no one seems to know the previous point of contact. Stylishly, the film has a sophisticated luxurious look. We are taken to see how these people live and the world they live in their own habitat.<br /><br />The only thing one gets out of all these souls in the picture is the different stages of loneliness each one inhabits. A big city is not exactly the best place in which human relations find sincere fulfillment, as one discerns is the case wi...  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Gbcp65zz_7wk",
        "outputId": "13807773-eba5-4cff-c10c-a80c3e2b6a83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"The number of rows and columns in the dataset is: {}\".format(df.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of rows and columns in the dataset is: (50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_uP_hOAR_ac",
        "outputId": "672e5d30-7437-4185-c25e-43427c8ab721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Identify missing values\n",
        "df.apply(lambda x: sum(x.isnull()), axis=0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AelQrBAeAEuJ",
        "outputId": "6e819909-7fe6-49b4-b70e-e7a19406fcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Check the target class balance\n",
        "df[\"sentiment\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    25000\n",
              "positive    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ESyS2xsQbQlm",
        "colab": {}
      },
      "source": [
        "# Functions for constructing BERT Embeddings: input_ids, input_masks, input_segments and Inputs\n",
        "MAX_SEQ_LEN=500 # max sequence length\n",
        "\n",
        "def get_masks(tokens):\n",
        "    \"\"\"Masks: 1 for real tokens and 0 for paddings\"\"\"\n",
        "    return [1]*len(tokens) + [0] * (MAX_SEQ_LEN - len(tokens))\n",
        " \n",
        "def get_segments(tokens):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"  \n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (MAX_SEQ_LEN - len(tokens))\n",
        "\n",
        "def get_ids(tokens, tokenizer):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (MAX_SEQ_LEN - len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "def create_single_input(sentence, tokenizer, max_len):\n",
        "  \"\"\"Create an input from a sentence\"\"\"\n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "  stokens = stokens[:max_len]\n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        " \n",
        "  ids = get_ids(stokens, tokenizer)\n",
        "  masks = get_masks(stokens)\n",
        "  segments = get_segments(stokens)\n",
        "\n",
        "  return ids, masks, segments\n",
        " \n",
        "def convert_sentences_to_features(sentences, tokenizer):\n",
        "  \"\"\"Convert sentences to features: input_ids, input_masks and input_segments\"\"\"\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        " \n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "    ids,masks,segments=create_single_input(sentence,tokenizer,MAX_SEQ_LEN-2)\n",
        "    assert len(ids) == MAX_SEQ_LEN\n",
        "    assert len(masks) == MAX_SEQ_LEN\n",
        "    assert len(segments) == MAX_SEQ_LEN\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32), \n",
        "          np.asarray(input_masks, dtype=np.int32), \n",
        "          np.asarray(input_segments, dtype=np.int32)]\n",
        "\n",
        "def create_tonkenizer(bert_layer):\n",
        "    \"\"\"Instantiate Tokenizer with vocab\"\"\"\n",
        "    vocab_file=bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "    do_lower_case=bert_layer.resolved_object.do_lower_case.numpy() \n",
        "    tokenizer=bert.bert_tokenization.FullTokenizer(vocab_file,do_lower_case)\n",
        "    return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Xs6_p8VTgpoy"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C_mFZ2HRcRJB",
        "outputId": "d42dd5cc-b7c2-4b77-caf2-d1927123fb16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "def nlp_model(callable_object):\n",
        "    # Load saved BERT base model\n",
        "    bert_layer = hub.KerasLayer(handle=callable_object, trainable=True)  \n",
        "   \n",
        "    # BERT layer three inputs: ids, masks and segments\n",
        "    input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_ids\")           \n",
        "    input_masks = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"input_masks\")       \n",
        "    input_segments = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name=\"segment_ids\")\n",
        "    \n",
        "    inputs = [input_ids, input_masks, input_segments] # BERT inputs\n",
        "    pooled_output, sequence_output = bert_layer(inputs) # BERT outputs\n",
        "    \n",
        "    # Add a hidden layer\n",
        "    x = Dense(units=768, activation='relu')(pooled_output)\n",
        "    x = Dropout(0.1)(x)\n",
        " \n",
        "    # Add output layer\n",
        "    outputs = Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "    # Construct a new model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model = nlp_model(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "segment_ids (InputLayer)        [(None, 500)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_ids[0][0]                  \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 segment_ids[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 768)          590592      keras_layer[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 768)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            1538        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 110,074,371\n",
            "Trainable params: 110,074,370\n",
            "Non-trainable params: 1\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ViqJURL5qcZJ"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XL5LaS68Qo8G",
        "outputId": "92891546-0b66-4d50-fcd5-e70b4307852d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Create examples for training and testing\n",
        "df = df.sample(frac=1) # Shuffle the dataset\n",
        "tokenizer = create_tonkenizer(model.layers[3])\n",
        "X_train = convert_sentences_to_features(df['review'][:40000], tokenizer)\n",
        "X_test = convert_sentences_to_features(df['review'][40000:], tokenizer)\n",
        "\n",
        "df['sentiment'].replace('positive',1.,inplace=True)\n",
        "df['sentiment'].replace('negative',0.,inplace=True)\n",
        "one_hot_encoded = to_categorical(df['sentiment'].values)\n",
        "y_train = one_hot_encoded[:40000]\n",
        "y_test =  one_hot_encoded[40000:]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [02:35<00:00, 256.66it/s]\n",
            "100%|██████████| 10000/10000 [00:38<00:00, 258.95it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IzSF2HJi5XsY",
        "outputId": "3dd8ac00-17fd-4bbd-ce9a-53b1623ea8ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Train the model\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 1\n",
        "\n",
        "# Use Adam optimizer to minimize the categorical_crossentropy loss\n",
        "opt = Adam(learning_rate=2e-5)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit data to the model\n",
        "history = model.fit(X_train, y_train,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    epochs=EPOCHS,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    verbose = 1)\n",
        "\n",
        "model.save('nlp_model.h5') "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5000/5000 [==============================] - 2803s 561ms/step - loss: 0.2111 - accuracy: 0.9155 - val_loss: 0.1589 - val_accuracy: 0.9409\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "toHq_3_Am6if"
      },
      "source": [
        "## Analysis of model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fcuvU9EhiFXX",
        "colab": {}
      },
      "source": [
        "# Load the pretrained nlp_model\n",
        "from tensorflow.keras.models import load_model\n",
        "new_model = load_model('nlp_model.h5',custom_objects={'KerasLayer':hub.KerasLayer})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KCqF3D54iGiZ",
        "colab": {}
      },
      "source": [
        "# Predict on test dataset\n",
        "from sklearn.metrics import classification_report\n",
        "pred_test = np.argmax(new_model.predict(X_test), axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6pcfuN3wvFJV",
        "outputId": "734f838e-c805-4784-d545-e0e74f7f5a37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print(classification_report(np.argmax(y_test,axis=1), pred_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94      4960\n",
            "           1       0.94      0.95      0.94      5040\n",
            "\n",
            "    accuracy                           0.94     10000\n",
            "   macro avg       0.94      0.94      0.94     10000\n",
            "weighted avg       0.94      0.94      0.94     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZxyAqz094Lzv",
        "outputId": "ef3c36d5-493f-4af9-a4dc-5d1c3043253b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pred_test[:10]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 0, 1, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "trYqvx4fvrXY",
        "outputId": "760c9a95-9eba-4fa6-e2b6-9c301eb9fe9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Predicted 0 for the first review in the test dataset\n",
        "df['review'][40000:40001]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13847    This was really a very bad movie. I am a huge fan of Italian Horror, Argento, Mario Bava, Fulci and yes, even our good friend here Lamberto sometimes comes out with a good one. I found the first two 'Demons' films to be highly entertaining - they were so bad they were great but this one is just so bad that it is really, really bad. It is intensely boring, the story never goes anywhere and I hated the characters - the wife slapping husband and whiny cry-baby pain in the *** wife drove me mad, there was nowhere near enough of the story devoted to the Ogre who was probably the best actor in the whole film. I turned it off about three quarters of the way through because I was very, very BORED! Don't bother.\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tut0mHIywx09",
        "outputId": "42b575ce-f44a-4990-8221-db668071e383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Predicted 1 for the second review in the test dataset\n",
        "df['review'][40001:40002]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16375    In a performance both volatile and graceful, Al Pacino re-teams with Sea of Love director, Harold Becker.<br /><br />As New York Mayor John Pappas in City Hall.<br /><br />A savvy thriller thats the first film ever shot inside the lower Manhattan structure that's ground zero for the City's government.<br /><br />That the other NYC locations provide the vivid settings as an idealistic mayoral aide (John Cusack) follows a trail of subversion and cover-up that may loop back to the man he serves and reveres.<br /><br />Bridget Fonda, Danny Aiello, Martin Landau, Tony Franciosa and David Paymer add more starry brilliance to this gripping tale of power.<br /><br />And the power behind power.\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5R89wjoCxaRU",
        "outputId": "d6094c4d-4ebe-4226-da63-a67db36e3325",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Predicted 1 for the third review in the test dataset\n",
        "df['review'][40002:40003]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41263    Despite its budget limitations, this is a great film, proof that effort and imagination can overcome lack of cash. The opening, in which cave-paintings seem to show how some dinosaurs at least survived into the age of human beings, is a nice red herring. After that, a meteor comes down into a lake and causes heat which, in turn, causes the hatching of a frozen dinosaur egg (maybe the cave-paintings suggest instead that this isn't the first time such a thing has happened). When the prehistoric beast appears, it's a well-animated Plesiosaur which is soon causing disappearances in the local area. Alright, so it's not Jurassic Park, but it's still genuine entertainment for fans of monster movies.\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    }
  ]
}